{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellarium.ml import CellariumModule, CellariumPipeline\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "DEVICE = torch.device('cuda:6')\n",
    "sc.set_figure_params(figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "CHECKPOINTS_PATH = \"/mnt/cellariumgpt-xfer/100M_long_run/run_001/lightning_logs/version_0/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an AnnData extract\n",
    "adata_path = os.path.join(ROOT_PATH, \"data\", \"extract_0.h5ad\")\n",
    "adata = sc.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ontology_infos = dict()\n",
    "\n",
    "ref_obs = adata.obs\n",
    "\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"] = dict()\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"names\"] = list(ref_obs['assay_ontology_term_id'].cat.categories)  \n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"labels\"] = list(ref_obs['assay_ontology_term_id'].cat.categories) # just because I am lazy\n",
    "\n",
    "gene_ontology_infos[\"suspension_type\"] = dict()\n",
    "gene_ontology_infos[\"suspension_type\"][\"names\"] = list(ref_obs['suspension_type'].cat.categories)  # for uniformity -- this variable does not have an ontology (does it?)\n",
    "gene_ontology_infos[\"suspension_type\"][\"labels\"] = list(ref_obs['suspension_type'].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene IDs, gene symbols, useful maps\n",
    "model_var_names = np.asarray(adata.var_names)\n",
    "model_var_names_set = set(model_var_names)\n",
    "var_name_to_index_map = {var_name: i for i, var_name in enumerate(model_var_names)}\n",
    "\n",
    "gene_info_tsv_path = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "gene_info_df = pd.read_csv(gene_info_tsv_path, sep=\"\\t\")\n",
    "\n",
    "gene_symbol_to_gene_id_map = dict()\n",
    "for gene_symbol, gene_id in zip(gene_info_df['Gene Symbol'], gene_info_df['ENSEMBL Gene ID']):\n",
    "    if gene_symbol != float('nan'):\n",
    "        gene_symbol_to_gene_id_map[gene_symbol] = gene_id\n",
    "\n",
    "gene_id_to_gene_symbol_map = {gene_id: gene_symbol for gene_symbol, gene_id in gene_symbol_to_gene_id_map.items()}\n",
    "for gene_id in model_var_names:\n",
    "    if gene_id not in gene_id_to_gene_symbol_map:\n",
    "        gene_id_to_gene_symbol_map[gene_id] = gene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv(os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"manifest.csv\"), index_col=0)\n",
    "\n",
    "# reset index to go from 1 to ...\n",
    "validation_df.index += 1\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(validation_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process a given validation AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# val_idx_list = [58, 66, 69, 53, 67, 92, 107, 108]\n",
    "val_idx_list = [92, 93, 100, 104, 40, 52, 50, 79]\n",
    "N_TOP_HVG = 5000\n",
    "\n",
    "for val_idx in tqdm(val_idx_list):\n",
    "\n",
    "    val_adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}.h5ad\")\n",
    "    val_adata = sc.read_h5ad(val_adata_path)\n",
    "\n",
    "    val_adata.layers['counts'] = val_adata.X.copy()\n",
    "\n",
    "    # normalize\n",
    "    sc.pp.normalize_total(val_adata, target_sum=1e4)\n",
    "    sc.pp.log1p(val_adata)\n",
    "\n",
    "    # calculate mean log TPKC\n",
    "    val_adata.var['mean_log_tpkc'] = np.asarray(val_adata.X.mean(axis=0)).flatten()\n",
    "\n",
    "    # make an embedding\n",
    "    sc.pp.highly_variable_genes(val_adata, n_top_genes=N_TOP_HVG)\n",
    "    val_adata = val_adata[:, val_adata.var['highly_variable']]\n",
    "\n",
    "    sc.pp.scale(val_adata, max_value=10)\n",
    "    sc.pp.pca(val_adata, n_comps=50)\n",
    "    sc.pp.neighbors(val_adata, n_pcs=50, n_neighbors=30)\n",
    "    sc.tl.umap(val_adata)\n",
    "\n",
    "    val_adata.write_h5ad(os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}__processed.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pool all the HVGs together\n",
    "\n",
    "- For duplicates, choose the higher TPKK\n",
    "- Sort by TPKK and choose:\n",
    "  - 5000 genes for prompting\n",
    "  - 15000 genes for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "val_idx_list = [92, 93, 100, 104, 40, 52, 50, 79]\n",
    "N_PROMPT_GENES = 5000\n",
    "\n",
    "hvg_dict = dict()\n",
    "hvg_dict['dataset_index'] = []\n",
    "hvg_dict['gene_id'] = []\n",
    "hvg_dict['log_tpkc'] = []\n",
    "\n",
    "for val_idx in tqdm(val_idx_list):\n",
    "\n",
    "    adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}__processed.h5ad\")\n",
    "    adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "    n_hvg = adata.shape[1]\n",
    "    hvg_dict['dataset_index'] += [val_idx] * n_hvg\n",
    "    hvg_dict['gene_id'] += adata.var.index.tolist()\n",
    "    hvg_dict['log_tpkc'] += adata.var['mean_log_tpkc'].tolist()\n",
    "\n",
    "hvg_df = pd.DataFrame(hvg_dict)\n",
    "\n",
    "# now, group by gene_id, and choose the row with highest log_tpkc;  drop other rows\n",
    "hvg_df = hvg_df.sort_values('log_tpkc', ascending=False).groupby('gene_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg_df['gene_symbol'] = hvg_df['gene_id'].map(gene_id_to_gene_symbol_map)\n",
    "hvg_df = hvg_df.sort_values('log_tpkc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_gene_symbols = hvg_df['gene_symbol'].tolist()[:N_PROMPT_GENES]\n",
    "prompt_gene_ids = hvg_df['gene_id'].tolist()[:N_PROMPT_GENES]\n",
    "\n",
    "query_gene_symbols = hvg_df['gene_symbol'].tolist()\n",
    "query_gene_ids = hvg_df['gene_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hvg_df['log_tpkc'], bins=100, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "hvg_df.to_csv(os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"hvg_df.csv\"), index=False)\n",
    "\n",
    "pd.DataFrame(prompt_gene_ids).to_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"prompt_gene_ids.csv\"), index=False, header=False)\n",
    "\n",
    "pd.DataFrame(query_gene_ids).to_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"query_gene_ids.csv\"), index=False, header=False)\n",
    "\n",
    "pd.DataFrame(prompt_gene_symbols).to_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"prompt_gene_symbols.csv\"), index=False, header=False)\n",
    "\n",
    "pd.DataFrame(query_gene_symbols).to_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"query_gene_symbols.csv\"), index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making metacells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "val_idx_list = [92, 93, 100, 104, 40, 52, 50, 79]\n",
    "N_PROMPT_GENES = 5000\n",
    "\n",
    "MIN_CELLS_PER_TYPE = 10\n",
    "MAX_CELLS_FOR_METACELL = 100\n",
    "\n",
    "\n",
    "hvg_dict = dict()\n",
    "hvg_dict['dataset_index'] = []\n",
    "hvg_dict['gene_id'] = []\n",
    "hvg_dict['log_tpkc'] = []\n",
    "\n",
    "for val_idx in tqdm(val_idx_list):\n",
    "\n",
    "    adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}__processed.h5ad\")\n",
    "    orig_adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}.h5ad\")\n",
    "    adata = sc.read_h5ad(adata_path)\n",
    "    orig_adata = sc.read_h5ad(orig_adata_path)\n",
    "\n",
    "    # how many cell types with as many cells above MIN_CELLS_PER_TYPE?\n",
    "    cell_type_count_dict = adata.obs['cell_type'].value_counts().to_dict()\n",
    "    filtered_cell_type_count_dict = dict()\n",
    "\n",
    "    for cell_type, count in cell_type_count_dict.items():\n",
    "        if count < MIN_CELLS_PER_TYPE:\n",
    "            print(f\"Skipping cell type {cell_type} in {val_idx} because cell type {cell_type} has only {count} cells\")\n",
    "        else:\n",
    "            filtered_cell_type_count_dict[cell_type] = count\n",
    "    \n",
    "    # for each cell type, select the cell with median total_mrna_umis, and then select up to MAX_CELLS_FOR_METACELL\n",
    "    for i_cell_type, cell_type in enumerate(filtered_cell_type_count_dict.keys()):\n",
    "        cell_type_adata = adata[adata.obs['cell_type'] == cell_type]\n",
    "        cell_type_adata = cell_type_adata[cell_type_adata.obs['total_mrna_umis'].sort_values().index]\n",
    "        median_idx = cell_type_adata.shape[0] // 2\n",
    "        median_cell_id = cell_type_adata.obs['original_cell_id'].iloc[median_idx]\n",
    "        median_pc_k = cell_type_adata.obsm['X_pca'][median_idx, :]\n",
    "\n",
    "        # sort other cells based on cosine distance to median_pc_k\n",
    "        median_pc_unit_k = median_pc_k / np.linalg.norm(median_pc_k)\n",
    "        other_cells_unit_nk = cell_type_adata.obsm['X_pca'] / np.linalg.norm(cell_type_adata.obsm['X_pca'], axis=1)[:, None]\n",
    "        cell_type_adata.obs['distance_to_median'] = np.linalg.norm(other_cells_unit_nk - median_pc_unit_k, axis=1)\n",
    "        cell_type_adata = cell_type_adata[cell_type_adata.obs['distance_to_median'].sort_values().index]\n",
    "        assert cell_type_adata.obs['original_cell_id'].iloc[0] == median_cell_id\n",
    "        \n",
    "        # select up to MAX_CELLS_FOR_METACELL\n",
    "        cell_type_adata = cell_type_adata[:min(MAX_CELLS_FOR_METACELL, cell_type_adata.shape[0])]\n",
    "        orig_cell_type_adata = orig_adata[orig_adata.obs['original_cell_id'].isin(cell_type_adata.obs['original_cell_id'])]\n",
    "        assert len(orig_cell_type_adata) == len(cell_type_adata)\n",
    "\n",
    "        # write to disk\n",
    "        orig_cell_type_adata.write_h5ad(\n",
    "            os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", f\"extract_{val_idx}__{i_cell_type}.h5ad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
