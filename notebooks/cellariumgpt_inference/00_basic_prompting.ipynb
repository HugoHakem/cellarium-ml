{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic stuff\n",
    "\n",
    "Interesting questions:\n",
    "- What happens if we iterate on a cell? do we reach a fixed point or not?\n",
    "- What happens when we include or not include metadata tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellarium.ml import CellariumModule, CellariumPipeline\n",
    "\n",
    "DEVICE = torch.device('cuda:7')\n",
    "sc.set_figure_params(figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "CHECKPOINTS_PATH = \"/mnt/cellariumgpt-xfer/100M_long_run/run_001/lightning_logs/version_0/checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an AnnData Extract\n",
    "\n",
    "We will use it for category mappings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an AnnData extract\n",
    "adata_path = os.path.join(ROOT_PATH, \"data\", \"extract_0.h5ad\")\n",
    "adata = sc.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ontology_infos = dict()\n",
    "\n",
    "ref_obs = adata.obs\n",
    "\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"] = dict()\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"names\"] = list(ref_obs['assay_ontology_term_id'].cat.categories)  \n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"labels\"] = list(ref_obs['assay_ontology_term_id'].cat.categories) # just because I am lazy\n",
    "\n",
    "gene_ontology_infos[\"suspension_type\"] = dict()\n",
    "gene_ontology_infos[\"suspension_type\"][\"names\"] = list(ref_obs['suspension_type'].cat.categories)  # for uniformity -- this variable does not have an ontology (does it?)\n",
    "gene_ontology_infos[\"suspension_type\"][\"labels\"] = list(ref_obs['suspension_type'].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene IDs, gene symbols, useful maps\n",
    "model_var_names = np.asarray(adata.var_names)\n",
    "model_var_names_set = set(model_var_names)\n",
    "var_name_to_index_map = {var_name: i for i, var_name in enumerate(model_var_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_info_tsv_path = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "gene_info_df = pd.read_csv(gene_info_tsv_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_symbol_to_gene_id_map = dict()\n",
    "for gene_symbol, gene_id in zip(gene_info_df['Gene Symbol'], gene_info_df['ENSEMBL Gene ID']):\n",
    "    if gene_symbol != float('nan'):\n",
    "        gene_symbol_to_gene_id_map[gene_symbol] = gene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful stuff:\n",
    "- `model_var_names`\n",
    "- `model_gene_symbols`\n",
    "- `var_name_to_index_map`\n",
    "- `gene_symbol_to_gene_id_map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a CellariumGPT checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(CHECKPOINTS_PATH, \"epoch=2-step=252000.ckpt\")\n",
    "gpt_model = CellariumModule.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "# Inject gene categories\n",
    "gpt_model.model.gene_categories = np.asarray(adata.var_names)\n",
    "\n",
    "# change attention backend to memory efficient\n",
    "gpt_model.model.set_attention_backend('mem_efficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ontology infos from the TrainTokenizer, which is the first step of the pipeline\n",
    "metadata_ontology_infos = gpt_model.pipeline[0].ontology_infos\n",
    "print(type(metadata_ontology_infos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellarium.ml.models.cellarium_gpt import PredictTokenizer\n",
    "\n",
    "# Rewire the pipeline with a PredictTokenizer\n",
    "predict_tokenizer = PredictTokenizer(\n",
    "    max_total_mrna_umis=100_000,\n",
    "    gene_vocab_sizes={\n",
    "        \"assay\": 19,\n",
    "        \"gene_id\": 36601,\n",
    "        \"gene_value\": 2001,\n",
    "        \"suspension_type\": 2,\n",
    "    },\n",
    "    metadata_vocab_sizes={\n",
    "        \"cell_type\": 890,\n",
    "        \"development_stage\": 191,\n",
    "        \"disease\": 350,\n",
    "        \"sex\": 2,\n",
    "        \"tissue\": 822,\n",
    "    },\n",
    "    ontology_infos=metadata_ontology_infos,\n",
    ")\n",
    "\n",
    "gpt_model.pipeline = CellariumPipeline([\n",
    "    predict_tokenizer,\n",
    "    gpt_model.model,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cellarium.ml.models.cellarium_gpt import CellariumGPT\n",
    "\n",
    "\n",
    "def generate_tokens_from_adata(\n",
    "        adata: sc.AnnData,\n",
    "        gene_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        metadata_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        model_gene_categories: list[str],\n",
    "        obs_index: int | list[int] | None,\n",
    "        query_var_index: list[int],\n",
    "        query_total_mrna_umis: float | None,\n",
    "        metadata_prompt_masks_dict: dict[str, bool],\n",
    "        tokenizer: PredictTokenizer,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ) -> tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "\n",
    "    .. note::\n",
    "      All variables in the AnnData are treated as prompts.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # slice the anndata\n",
    "    if isinstance(obs_index, int):\n",
    "        obs_index = [obs_index]\n",
    "\n",
    "    # save obs before slicing\n",
    "    if obs_index is not None:\n",
    "        adata = adata[obs_index]\n",
    "\n",
    "    # generate gene ids and masks\n",
    "    n_cells = len(adata)\n",
    "    adata_var_names = adata.var_names\n",
    "    model_var_name_to_index_map = {var_name: var_index for var_index, var_name in enumerate(model_gene_categories)}\n",
    "    assert all([var_name in model_var_name_to_index_map for var_name in adata_var_names])\n",
    "    prompt_var_index = [model_var_name_to_index_map[var_name] for var_name in adata_var_names]\n",
    "    n_prompt_vars = len(prompt_var_index)\n",
    "    n_query_vars = len(query_var_index)\n",
    "    n_total_vars = n_prompt_vars + n_query_vars\n",
    "    \n",
    "    # gene id\n",
    "    gene_ids_nc = torch.tensor(\n",
    "        prompt_var_index + query_var_index,\n",
    "        dtype=torch.int64, device=device)[None, :].expand(n_cells, n_total_vars)\n",
    "    \n",
    "    # gene prompt mask\n",
    "    gene_prompt_mask_nc = torch.tensor(\n",
    "        [1] * n_prompt_vars + [0] * n_query_vars,\n",
    "        dtype=torch.bool, device=device)[None, :].expand(n_cells, n_total_vars)\n",
    "    \n",
    "    # gene value\n",
    "    try:\n",
    "        prompt_X_ng = np.asarray(adata.X.todense())\n",
    "    except AttributeError:\n",
    "        prompt_X_ng = adata.X\n",
    "    prompt_gene_value_nc = torch.tensor(prompt_X_ng, dtype=torch.float32, device=device)\n",
    "    query_gene_value_nc = torch.zeros(n_cells, n_query_vars, dtype=torch.float32, device=device)\n",
    "    gene_value_nc = torch.cat([prompt_gene_value_nc, query_gene_value_nc], dim=1)\n",
    "\n",
    "    # total mrna umis\n",
    "    prompt_total_mrna_umis_nc = torch.tensor(\n",
    "        adata.obs[\"total_mrna_umis\"].values,\n",
    "        dtype=torch.float32, device=device)[:, None].expand(n_cells, n_prompt_vars)\n",
    "    if query_total_mrna_umis is None:\n",
    "        # the same as prompt\n",
    "        query_total_mrna_umis_nc = torch.tensor(\n",
    "            adata.obs[\"total_mrna_umis\"].values,\n",
    "            dtype=torch.float32, device=device)[:, None].expand(n_cells, n_query_vars)\n",
    "    else:\n",
    "        query_total_mrna_umis_nc = torch.tensor(\n",
    "            [query_total_mrna_umis] * n_cells,\n",
    "            dtype=torch.float32, device=device)[:, None].expand(n_cells, n_query_vars)\n",
    "    total_mrna_umis_nc = torch.cat([prompt_total_mrna_umis_nc, query_total_mrna_umis_nc], dim=1)\n",
    "\n",
    "    # convert assay and suspension_type to codes\n",
    "    assay_nc = torch.tensor(\n",
    "        pd.Categorical(\n",
    "            adata.obs[\"assay_ontology_term_id\"].values,\n",
    "            categories=gene_ontology_infos[\"assay_ontology_term_id\"][\"names\"]).codes,\n",
    "        dtype=torch.int64, device=device)[:, None].expand(n_cells, n_total_vars)\n",
    "    suspension_type_nc = torch.tensor(\n",
    "        pd.Categorical(\n",
    "            adata.obs[\"suspension_type\"].values,\n",
    "            categories=gene_ontology_infos[\"suspension_type\"][\"names\"]).codes,\n",
    "        dtype=torch.int64, device=device)[:, None].expand(n_cells, n_total_vars)\n",
    "\n",
    "    gene_tokens_dict = {\n",
    "        \"assay\": assay_nc,  # categorical\n",
    "        \"suspension_type\": suspension_type_nc,  # categorical\n",
    "        \"gene_id\": gene_ids_nc,  # categorical\n",
    "        \"gene_value\": gene_value_nc,  # continuous\n",
    "        \"total_mrna_umis\": total_mrna_umis_nc,  # continuous\n",
    "    }\n",
    "\n",
    "    # metadata prompt masks\n",
    "    expanded_metadata_prompt_masks_dict = dict()\n",
    "    for key in metadata_ontology_infos.keys():  # note: key order is important ...\n",
    "        expanded_metadata_prompt_masks_dict[key] = torch.tensor(\n",
    "            [metadata_prompt_masks_dict[key]] * n_cells, dtype=torch.bool, device=device)\n",
    "    \n",
    "    # generate metadata tokens dicts; `PredictTokenizer` will convert these to codes\n",
    "    metadata_tokens_dict = {\n",
    "        \"cell_type\": adata.obs[\"cell_type_ontology_term_id\"].values,  # categorical\n",
    "        \"development_stage\": adata.obs[\"development_stage_ontology_term_id\"].values,  # categorical\n",
    "        \"disease\": adata.obs[\"disease_ontology_term_id\"].values,  # categorical\n",
    "        \"sex\": adata.obs[\"sex_ontology_term_id\"].values,  # categorical\n",
    "        \"tissue\": adata.obs[\"tissue_ontology_term_id\"].values,  # categorical\n",
    "    }\n",
    "\n",
    "    # where to find each thing in the context?\n",
    "    context_indices = dict()\n",
    "    context_indices['prompt_genes'] = np.arange(0, n_prompt_vars).tolist()\n",
    "    context_indices['query_genes'] = np.arange(n_prompt_vars, n_query_vars + n_prompt_vars).tolist()\n",
    "    offset = 0\n",
    "    for metadata_key in metadata_ontology_infos.keys():\n",
    "        context_indices[f'query_{metadata_key}'] = n_query_vars + n_prompt_vars + offset\n",
    "        offset += 1\n",
    "\n",
    "    # return gene_tokens_dict, metadata_tokens_dict\n",
    "    tokenizer_output = tokenizer(\n",
    "        metadata_tokens_n=metadata_tokens_dict,\n",
    "        metadata_prompt_masks_n=expanded_metadata_prompt_masks_dict,\n",
    "        gene_tokens_nc=gene_tokens_dict,\n",
    "        gene_prompt_mask_nc=gene_prompt_mask_nc,\n",
    "    )\n",
    "\n",
    "    return tokenizer_output, context_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the predict tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a test anndata\n",
    "test_adata_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"luca_CD8_ex_LUAD.h5ad\")\n",
    "test_adata = sc.read_h5ad(test_adata_path)\n",
    "\n",
    "# add total mNRA umis\n",
    "test_adata.obs['total_mrna_umis'] = test_adata.X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load top genes\n",
    "top_genes_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"immune_top_5000_genes.csv\")\n",
    "top_genes_df = pd.read_csv(top_genes_path)\n",
    "top_gene_ids = top_genes_df['gene_id'].values\n",
    "\n",
    "# restrict top_gene_ids to those in the model categories\n",
    "top_gene_ids = [gene_id for gene_id in top_gene_ids if gene_id in model_var_names_set]\n",
    "print(len(top_gene_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_adata = test_adata[:, top_gene_ids][[0]]\n",
    "\n",
    "metadata_prompt_masks_dict = {\n",
    "    \"cell_type\": False,\n",
    "    \"development_stage\": False,\n",
    "    \"disease\": False,\n",
    "    \"sex\": False,\n",
    "    \"tissue\": False,\n",
    "}\n",
    "\n",
    "query_var_index = [var_name_to_index_map[gene_id] for gene_id in top_gene_ids]\n",
    "\n",
    "tokens_dict, context_indices = generate_tokens_from_adata(\n",
    "    adata=input_adata,\n",
    "    gene_ontology_infos=gene_ontology_infos,\n",
    "    metadata_ontology_infos=metadata_ontology_infos,\n",
    "    model_gene_categories=model_var_names,\n",
    "    obs_index=None,\n",
    "    query_var_index=query_var_index,\n",
    "    query_total_mrna_umis=10_000,\n",
    "    metadata_prompt_masks_dict=metadata_prompt_masks_dict,\n",
    "    tokenizer=predict_tokenizer,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "# convert to cuda\n",
    "tokens_dict = gpt_model.transfer_batch_to_device(tokens_dict, gpt_model.device, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_dict = gpt_model.model.predict(\n",
    "        gene_tokens_nc=tokens_dict[\"gene_tokens_nc\"],\n",
    "        metadata_tokens_n=tokens_dict[\"metadata_tokens_n\"],\n",
    "        prompt_mask_nc=tokens_dict[\"prompt_mask_nc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_key = 'cell_type'\n",
    "metadata_logits_nk = logits_dict[metadata_key][:, context_indices[f'query_{metadata_key}'], :]\n",
    "metadata_logits_nk = metadata_logits_nk - torch.logsumexp(metadata_logits_nk, dim=1, keepdim=True)\n",
    "metadata_probs_nk = torch.exp(metadata_logits_nk)\n",
    "\n",
    "probs_k = metadata_probs_nk.cpu().numpy()[0]\n",
    "sort_order = np.argsort(probs_k)[::-1]\n",
    "\n",
    "for k in range(10):\n",
    "    prob = probs_k[sort_order[k]]\n",
    "    name = metadata_ontology_infos[metadata_key][\"labels\"][sort_order[k]]\n",
    "    print(f\"{name}: {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_logits_ngk = logits_dict['gene_value'][:, context_indices['query_genes'], :]\n",
    "gene_logits_ngk = gene_logits_ngk - torch.logsumexp(gene_logits_ngk, dim=-1, keepdim=True)\n",
    "gene_probs_ngk = torch.exp(gene_logits_ngk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_index = top_gene_ids.index(gene_symbol_to_gene_id_map['PTPRC'])\n",
    "plt.plot(gene_probs_ngk[0, gene_index, :].cpu().numpy())\n",
    "plt.xlim((0, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library size upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "query_total_mrna_umis_list = [1_000, 2_000, 3_000, 4_000, 5_000, 6_000, 7_000, 8_000, 9_000, 10_000, 15_000, 20_000]\n",
    "query_gene_symbol = 'PTPRC'\n",
    "MAX_X = 60\n",
    "means = []\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 4))\n",
    "\n",
    "for query_total_mrna_umis in query_total_mrna_umis_list:\n",
    "    input_adata = test_adata[:, top_gene_ids][[0]]\n",
    "\n",
    "    metadata_prompt_masks_dict = {\n",
    "        \"cell_type\": False,\n",
    "        \"development_stage\": False,\n",
    "        \"disease\": False,\n",
    "        \"sex\": False,\n",
    "        \"tissue\": False,\n",
    "    }\n",
    "\n",
    "    query_var_index = [var_name_to_index_map[gene_id] for gene_id in top_gene_ids]\n",
    "\n",
    "    tokens_dict, context_indices = generate_tokens_from_adata(\n",
    "        adata=input_adata,\n",
    "        gene_ontology_infos=gene_ontology_infos,\n",
    "        metadata_ontology_infos=metadata_ontology_infos,\n",
    "        model_gene_categories=model_var_names,\n",
    "        obs_index=None,\n",
    "        query_var_index=[var_name_to_index_map[gene_symbol_to_gene_id_map[query_gene_symbol]]],\n",
    "        query_total_mrna_umis=query_total_mrna_umis,\n",
    "        metadata_prompt_masks_dict=metadata_prompt_masks_dict,\n",
    "        tokenizer=predict_tokenizer,\n",
    "        device=torch.device(\"cpu\"),\n",
    "    )\n",
    "\n",
    "    # convert to cuda\n",
    "    with torch.no_grad():\n",
    "        tokens_dict = gpt_model.transfer_batch_to_device(tokens_dict, gpt_model.device, 0)\n",
    "\n",
    "        logits_dict = gpt_model.model.predict(\n",
    "            gene_tokens_nc=tokens_dict[\"gene_tokens_nc\"],\n",
    "            metadata_tokens_n=tokens_dict[\"metadata_tokens_n\"],\n",
    "            prompt_mask_nc=tokens_dict[\"prompt_mask_nc\"],\n",
    "        )\n",
    "\n",
    "        gene_logits_ngk = logits_dict['gene_value'][:, context_indices['query_genes'], :]\n",
    "        gene_logits_ngk = gene_logits_ngk - torch.logsumexp(gene_logits_ngk, dim=-1, keepdim=True)\n",
    "        gene_probs_ngk = torch.exp(gene_logits_ngk)\n",
    "\n",
    "    probs_k = gene_probs_ngk.cpu().numpy()[0, 0, :]\n",
    "    mean = np.sum(np.arange(0, probs_k.shape[-1]) * probs_k)\n",
    "    means.append(mean)\n",
    "\n",
    "    ax.plot(probs_k, label=f\"{query_total_mrna_umis}\")\n",
    "\n",
    "ax.set_xlim((0, MAX_X))\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Counts')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title(query_gene_symbol)\n",
    "ax.grid(False)\n",
    "\n",
    "# calculate the linear slope between query_total_mrna_umis_list and means\n",
    "slope = linregress(np.log(query_total_mrna_umis_list), np.log(means)).slope\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 4))\n",
    "\n",
    "ax.plot(query_total_mrna_umis_list, means, marker='o', label=f\"log-log slope: {slope:.2f}\")\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Total mRNA UMIs')\n",
    "ax.set_ylabel(f'Mean count')\n",
    "ax.set_title(f'{query_gene_symbol}')\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metacell prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a test anndata\n",
    "test_adata_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"luca_CD8_ex_LUAD.h5ad\")\n",
    "test_adata = sc.read_h5ad(test_adata_path)\n",
    "\n",
    "# add total mNRA umis\n",
    "test_adata.obs['total_mrna_umis'] = test_adata.X.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a metacell\n",
    "X_meta_g = np.asarray(test_adata.X.sum(0))\n",
    "\n",
    "# set total mrna umis to the mean of the dataset\n",
    "target_total_mrna_umis = np.mean(np.asarray(test_adata.X.sum(-1)).flatten())\n",
    "X_meta_g = X_meta_g * target_total_mrna_umis / X_meta_g.sum()\n",
    "\n",
    "# make a metacell anndata\n",
    "adata_meta = test_adata[0, :].copy()\n",
    "adata_meta.X = X_meta_g\n",
    "adata_meta.obs['total_mrna_umis'] = [target_total_mrna_umis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or choose a single cell\n",
    "# adata_meta = test_adata[5].copy()\n",
    "# adata_meta.obs['total_mrna_umis'] = [adata_meta.X.sum().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_meta.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose top genes\n",
    "top_genes_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"immune_top_5000_genes.csv\")\n",
    "top_genes_df = pd.read_csv(top_genes_path)\n",
    "top_gene_ids = top_genes_df['gene_id'].values\n",
    "\n",
    "# restrict top_gene_ids to those in the model categories\n",
    "top_gene_ids = [gene_id for gene_id in top_gene_ids if gene_id in model_var_names_set]\n",
    "print(len(top_gene_ids))\n",
    "prompt_gene_ids = top_gene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or random genes\n",
    "# n_random_genes = 7_000\n",
    "# prompt_gene_ids = np.random.choice(model_var_names, n_random_genes, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_adata = adata_meta[:, prompt_gene_ids]\n",
    "\n",
    "metadata_prompt_masks_dict = {\n",
    "    \"cell_type\": False,\n",
    "    \"development_stage\": False,\n",
    "    \"disease\": False,\n",
    "    \"sex\": False,\n",
    "    \"tissue\": False,\n",
    "}\n",
    "\n",
    "query_var_index = [var_name_to_index_map[gene_id] for gene_id in top_gene_ids]\n",
    "\n",
    "tokens_dict, context_indices = generate_tokens_from_adata(\n",
    "    adata=input_adata,\n",
    "    gene_ontology_infos=gene_ontology_infos,\n",
    "    metadata_ontology_infos=metadata_ontology_infos,\n",
    "    model_gene_categories=model_var_names,\n",
    "    obs_index=None,\n",
    "    query_var_index=query_var_index,\n",
    "    query_total_mrna_umis=None,\n",
    "    metadata_prompt_masks_dict=metadata_prompt_masks_dict,\n",
    "    tokenizer=predict_tokenizer,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "# convert to cuda\n",
    "tokens_dict = gpt_model.transfer_batch_to_device(tokens_dict, gpt_model.device, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_dict = gpt_model.model.predict(\n",
    "        gene_tokens_nc=tokens_dict[\"gene_tokens_nc\"],\n",
    "        metadata_tokens_n=tokens_dict[\"metadata_tokens_n\"],\n",
    "        prompt_mask_nc=tokens_dict[\"prompt_mask_nc\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_key = 'cell_type'\n",
    "metadata_logits_nk = logits_dict[metadata_key][:, context_indices[f'query_{metadata_key}'], :]\n",
    "metadata_logits_nk = metadata_logits_nk - torch.logsumexp(metadata_logits_nk, dim=1, keepdim=True)\n",
    "metadata_probs_nk = torch.exp(metadata_logits_nk)\n",
    "\n",
    "probs_k = metadata_probs_nk.cpu().numpy()[0]\n",
    "sort_order = np.argsort(probs_k)[::-1]\n",
    "\n",
    "for k in range(10):\n",
    "    prob = probs_k[sort_order[k]]\n",
    "    name = metadata_ontology_infos[metadata_key][\"labels\"][sort_order[k]]\n",
    "    print(f\"{name}: {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_logits_ngk = logits_dict['gene_value'][:, context_indices['query_genes'], :]\n",
    "gene_logits_ngk = gene_logits_ngk - torch.logsumexp(gene_logits_ngk, dim=-1, keepdim=True)\n",
    "gene_probs_ngk = torch.exp(gene_logits_ngk)\n",
    "gene_means_g = np.sum(np.arange(0, gene_probs_ngk.shape[-1]) * gene_probs_ngk.cpu().numpy()[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "try:\n",
    "    actual_X_g = np.asarray(input_adata.X.todense()).flatten()\n",
    "except AttributeError:\n",
    "    actual_X_g = input_adata.X.flatten()\n",
    "ax.scatter(\n",
    "    actual_X_g,\n",
    "    gene_means_g,\n",
    "    s=1\n",
    ")\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel('Metacell mean expression')\n",
    "ax.set_ylabel('CellariumGPT marginal mean expression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian-based gene-network construction\n",
    "\n",
    "- helper method to snap a cell to the mean manifold\n",
    "- differentiable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_tokens_from_adata(\n",
    "#         adata: sc.AnnData,\n",
    "#         gene_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "#         metadata_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "#         model_gene_categories: list[str],\n",
    "#         obs_index: int | list[int] | None,\n",
    "#         query_var_index: list[int],\n",
    "#         query_total_mrna_umis: float | None,\n",
    "#         metadata_prompt_masks_dict: dict[str, bool],\n",
    "#         tokenizer: PredictTokenizer,\n",
    "#         device: torch.device = torch.device(\"cpu\"),\n",
    "#     ) -> tuple[dict, dict]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_marginal_mean_manifold(\n",
    "        adata: sc.AnnData,\n",
    "        gene_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        metadata_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        query_var_names: list[str],\n",
    "        query_total_mrna_umis: float | None,\n",
    "        predict_tokenizer: PredictTokenizer,\n",
    "        cellarium_gpt_module: CellariumModule,\n",
    "        prompt_gene_values_g: torch.Tensor | None = None,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    assert len(adata) == 1, \"Only a single cell is allowed\"\n",
    "    \n",
    "    model_gene_categories = cellarium_gpt_module.model.gene_categories\n",
    "    var_name_to_index_map = {var_name: i for i, var_name in enumerate(model_gene_categories)}\n",
    "    query_var_index = [var_name_to_index_map[var_name] for var_name in query_var_names]\n",
    "\n",
    "    metadata_prompt_masks_dict = {\n",
    "        \"cell_type\": False,\n",
    "        \"development_stage\": False,\n",
    "        \"disease\": False,\n",
    "        \"sex\": False,\n",
    "        \"tissue\": False,\n",
    "    }\n",
    "\n",
    "    tokens_dict, context_indices = generate_tokens_from_adata(\n",
    "        adata=adata,\n",
    "        gene_ontology_infos=gene_ontology_infos,\n",
    "        metadata_ontology_infos=metadata_ontology_infos,\n",
    "        model_gene_categories=model_var_names,\n",
    "        obs_index=None,\n",
    "        query_var_index=query_var_index,\n",
    "        query_total_mrna_umis=query_total_mrna_umis,\n",
    "        metadata_prompt_masks_dict=metadata_prompt_masks_dict,\n",
    "        tokenizer=predict_tokenizer,\n",
    "        device=torch.device(\"cpu\"),\n",
    "    )\n",
    "\n",
    "    # convert to cuda\n",
    "    tokens_dict = cellarium_gpt_module.transfer_batch_to_device(tokens_dict, cellarium_gpt_module.device, 0)\n",
    "    \n",
    "    # get a reference to prompt gene values\n",
    "    FIRST_CELL_DIM = 0\n",
    "    GENE_VALUE_DIM = 0\n",
    "    prompt_gene_log1p_values_g = tokens_dict['gene_tokens_nc']['gene_value'][\n",
    "        FIRST_CELL_DIM, context_indices['prompt_genes'], GENE_VALUE_DIM]\n",
    "    \n",
    "    # this is the \"source\"\n",
    "    if prompt_gene_values_g is None:\n",
    "        prompt_gene_values_g = torch.expm1(prompt_gene_log1p_values_g).clone()\n",
    "    \n",
    "    # inject back to tokens_dict to re-establish the reference for Jacobian calculation\n",
    "    tokens_dict['gene_tokens_nc']['gene_value'][\n",
    "        FIRST_CELL_DIM, context_indices['prompt_genes'], GENE_VALUE_DIM] = torch.log1p(prompt_gene_values_g)\n",
    "\n",
    "    # get model predictions\n",
    "    logits_dict = cellarium_gpt_module.model.predict(\n",
    "        gene_tokens_nc=tokens_dict[\"gene_tokens_nc\"],\n",
    "        metadata_tokens_n=tokens_dict[\"metadata_tokens_n\"],\n",
    "        prompt_mask_nc=tokens_dict[\"prompt_mask_nc\"],\n",
    "    )\n",
    "\n",
    "    # note: we use `q` to denote query genes\n",
    "    gene_logits_qk = logits_dict['gene_value'][FIRST_CELL_DIM, context_indices['query_genes'], :]\n",
    "    gene_logits_qk = gene_logits_qk - torch.logsumexp(gene_logits_qk, dim=-1, keepdim=True)\n",
    "    log_counts_k = torch.arange(0, gene_logits_qk.shape[-1], device=gene_logits_qk.device).log()\n",
    "    gene_marginal_means_q = torch.logsumexp(gene_logits_qk + log_counts_k[None, :], dim=-1).exp()\n",
    "\n",
    "    return prompt_gene_values_g, gene_marginal_means_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test snap to marginal mean manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a test anndata\n",
    "test_adata_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"luca_CD8_ex_LUAD.h5ad\")\n",
    "test_adata = sc.read_h5ad(test_adata_path)\n",
    "\n",
    "# add total mNRA umis\n",
    "test_adata.obs['total_mrna_umis'] = test_adata.X.sum(axis=1)\n",
    "\n",
    "# make a metacell\n",
    "X_meta_g = np.asarray(test_adata.X.sum(0))\n",
    "\n",
    "# set total mrna umis to the mean of the dataset\n",
    "target_total_mrna_umis = np.mean(np.asarray(test_adata.X.sum(-1)).flatten())\n",
    "X_meta_g = X_meta_g * target_total_mrna_umis / X_meta_g.sum()\n",
    "\n",
    "# make a metacell anndata\n",
    "adata_meta = test_adata[0, :].copy()\n",
    "adata_meta.X = X_meta_g\n",
    "adata_meta.obs['total_mrna_umis'] = [target_total_mrna_umis]\n",
    "\n",
    "# choose top genes\n",
    "top_genes_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"immune_top_5000_genes.csv\")\n",
    "top_genes_df = pd.read_csv(top_genes_path)\n",
    "top_gene_ids = top_genes_df['gene_id'].values\n",
    "\n",
    "# restrict top_gene_ids to those in the model categories\n",
    "top_gene_ids = [gene_id for gene_id in top_gene_ids if gene_id in model_var_names_set]\n",
    "prompt_gene_ids = top_gene_ids\n",
    "\n",
    "MAX_GENES = 1000\n",
    "adata_meta = adata_meta[:, prompt_gene_ids[:MAX_GENES]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_gene_values_g, gene_marginal_means_q = snap_to_marginal_mean_manifold(\n",
    "    adata=adata_meta,\n",
    "    gene_ontology_infos=gene_ontology_infos,\n",
    "    metadata_ontology_infos=metadata_ontology_infos,\n",
    "    query_var_names=prompt_gene_ids[:MAX_GENES],\n",
    "    query_total_mrna_umis=None,\n",
    "    predict_tokenizer=predict_tokenizer,\n",
    "    cellarium_gpt_module=gpt_model,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "ax.scatter(\n",
    "    prompt_gene_values_g.detach().cpu().numpy(),\n",
    "    gene_marginal_means_q.detach().cpu().numpy(),\n",
    "    s=1)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Metacell mean expression')\n",
    "ax.set_ylabel('CellariumGPT marginal mean expression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Jacobian calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a test anndata\n",
    "test_adata_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"luca_CD8_ex_LUAD.h5ad\")\n",
    "test_adata = sc.read_h5ad(test_adata_path)\n",
    "\n",
    "# add total mNRA umis\n",
    "test_adata.obs['total_mrna_umis'] = test_adata.X.sum(axis=1)\n",
    "\n",
    "# make a metacell\n",
    "X_meta_g = np.asarray(test_adata.X.sum(0))\n",
    "\n",
    "# set total mrna umis to the mean of the dataset\n",
    "target_total_mrna_umis = np.mean(np.asarray(test_adata.X.sum(-1)).flatten())\n",
    "X_meta_g = X_meta_g * target_total_mrna_umis / X_meta_g.sum()\n",
    "\n",
    "# make a metacell anndata\n",
    "adata_meta = test_adata[0, :].copy()\n",
    "adata_meta.X = X_meta_g\n",
    "adata_meta.obs['total_mrna_umis'] = [target_total_mrna_umis]\n",
    "\n",
    "# choose top genes\n",
    "top_genes_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"immune_top_5000_genes.csv\")\n",
    "top_genes_df = pd.read_csv(top_genes_path)\n",
    "top_gene_ids = top_genes_df['gene_id'].values\n",
    "\n",
    "# restrict top_gene_ids to those in the model categories\n",
    "top_gene_ids = [gene_id for gene_id in top_gene_ids if gene_id in model_var_names_set]\n",
    "prompt_gene_ids = top_gene_ids\n",
    "\n",
    "MAX_GENES = 100\n",
    "adata_meta = adata_meta[:, prompt_gene_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_var_names = prompt_gene_ids\n",
    "\n",
    "prompt_gene_values_g = torch.tensor(\n",
    "    adata_meta.X[0].toarray().flatten(),\n",
    "    device=gpt_model.device,\n",
    "    dtype=torch.float32)\n",
    "\n",
    "def _wrapped_snap_to_marginal_mean_manifold(\n",
    "        prompt_gene_values_g: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    return snap_to_marginal_mean_manifold(\n",
    "        adata=adata_meta,\n",
    "        gene_ontology_infos=gene_ontology_infos,\n",
    "        metadata_ontology_infos=metadata_ontology_infos,\n",
    "        query_var_names=query_var_names,\n",
    "        query_total_mrna_umis=None,\n",
    "        predict_tokenizer=predict_tokenizer,\n",
    "        cellarium_gpt_module=gpt_model,\n",
    "        prompt_gene_values_g=prompt_gene_values_g,\n",
    "    )[1]\n",
    "\n",
    "jacobian_qg = torch.autograd.functional.jacobian(\n",
    "    func=_wrapped_snap_to_marginal_mean_manifold, \n",
    "    inputs=prompt_gene_values_g,\n",
    "    create_graph=False,\n",
    "    vectorize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_jacobian_qg = jacobian_qg.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacbian_by_jacrev = torch.func.jacrev(_wrapped_snap_to_marginal_mean_manifold)\n",
    "# jacbian_by_jacfwd = torch.func.jacfwd(_wrapped_snap_to_marginal_mean_manifold)\n",
    "\n",
    "# jacrev_jacobian_qg = jacbian_by_jacfwd(prompt_gene_values_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
