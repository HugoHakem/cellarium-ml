{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Analyze metadata predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as t\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set the logging level\n",
    "\n",
    "# Create a handler\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Create and set a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# To suppress the stupid AnnData warning ...\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Transforming to str index.\")\n",
    "\n",
    "from cellarium.ml.utilities.inference.cellarium_gpt_inference import \\\n",
    "    CellariumGPTInferenceContext\n",
    "from cellarium.ml.utilities.inference.metadata_benchmarking.calculate_metrics import \\\n",
    "    calculate_metrics_for_prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/home/mehrtash/data\"\n",
    "METADATA_PREDICTIONS_ROOT_PATH = os.path.join(ROOT_PATH, \"data\", \"metadata_predictions\")\n",
    "PREFIX_LIST = [\n",
    "    \"10M_001_bs1536\",\n",
    "    \"19M_001_bs2048\",\n",
    "    \"30M_001_bs2560\",\n",
    "    \"100M_long_run_last\"\n",
    "]\n",
    "VAL_ADATA_IDX_RANGE = np.arange(1, 111)\n",
    "N_HOPS_DICT = {\n",
    "    'cell_type': 3,\n",
    "    'development_stage': 3,\n",
    "    'disease': 3,\n",
    "    'tissue': 3,\n",
    "    'sex': 0,\n",
    "}\n",
    "\n",
    "def load_predictions_anndata(val_adata_idx: int, prefix_idx: int) -> sc.AnnData:\n",
    "    path = os.path.join(\n",
    "        METADATA_PREDICTIONS_ROOT_PATH,\n",
    "        PREFIX_LIST[prefix_idx],\n",
    "        f\"extract_{VAL_ADATA_IDX_RANGE[val_adata_idx]}_metadata_prediction_scores.h5ad\")\n",
    "    return sc.read_h5ad(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "results = defaultdict(list)\n",
    "top_k_list = [1, 3, 5, 10]\n",
    "\n",
    "for prefix_idx in tqdm(range(len(PREFIX_LIST))):\n",
    "    prefix = PREFIX_LIST[prefix_idx]\n",
    "    \n",
    "    for val_adata_idx in tqdm(range(len(VAL_ADATA_IDX_RANGE))):\n",
    "        val_adata_id = VAL_ADATA_IDX_RANGE[val_adata_idx]\n",
    "        meta_adata = load_predictions_anndata(val_adata_idx, prefix_idx)\n",
    "        results[\"prefix\"].append(prefix)\n",
    "        results[\"val_adata_id\"].append(val_adata_id)\n",
    "\n",
    "        for key in [\"cell_type\", \"disease\", \"development_stage\", \"tissue\", \"sex\"]:            \n",
    "            terms = meta_adata.uns[f\"{key}_ontology_term_ids\"]\n",
    "            mapper = {term: idx for idx, term in enumerate(terms)}\n",
    "\n",
    "            # logits_nk = meta_adata.obsm[f\"{key}_class_logits\"]\n",
    "            probs_nk = meta_adata.obsm[f\"{key}_class_probs\"]\n",
    "            labels_n = np.asarray(meta_adata.obs[f\"{key}_ontology_term_id\"].map(mapper).values)\n",
    "\n",
    "            # drop nans\n",
    "            valid_indices = ~np.isnan(labels_n)\n",
    "            probs_nk = probs_nk[valid_indices]\n",
    "            labels_n = labels_n[valid_indices].astype(int)  \n",
    "\n",
    "            if len(labels_n) == 0:\n",
    "                for top_k in top_k_list:\n",
    "                    results[f\"{key}_top_{top_k}_accuracy\"].append(np.nan)\n",
    "                # results[f\"{key}_auc\"].append(np.nan)\n",
    "                # results[f\"{key}_loss\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            # get top k predictions\n",
    "            for top_k in top_k_list:\n",
    "                top_k_indices = np.argsort(probs_nk, axis=1)[:, -top_k:]\n",
    "                top_k_probs = np.take_along_axis(probs_nk, top_k_indices, axis=1)\n",
    "\n",
    "                # calculate top k accuracy\n",
    "                pred_label_n = np.any(top_k_indices == labels_n[:, None], axis=1).astype(int)\n",
    "                top_k_accuracy = np.mean(pred_label_n)\n",
    "                results[f\"{key}_top_{top_k}_accuracy\"].append(top_k_accuracy)\n",
    "\n",
    "            # # Assume classifier.classes_ gives the full set of classes.\n",
    "            # classes = np.arange(probs_nk.shape[1])\n",
    "            # label_bin_nk = label_binarize(labels_n, classes=classes)\n",
    "            # if len(classes) == 2:\n",
    "            #     # binary AUC\n",
    "            #     auc = roc_auc_score(labels_n, probs_nk[:, 1])\n",
    "            # else:\n",
    "            #     auc = roc_auc_score(label_bin_nk, probs_nk, multi_class='ovr', average='micro')\n",
    "            # results[f\"{key}_auc\"].append(auc)\n",
    "\n",
    "            # # loss\n",
    "            # truth_names = meta_adata.obs[f\"{key}_ontology_term_id\"].values\n",
    "            # truth_indices = np.asarray(list(map(mapper.get, truth_names)))\n",
    "            # weights = np.ones_like(truth_indices)\n",
    "            # bad_indices = [idx for idx in range(len(truth_names)) if truth_names[idx] not in mapper]\n",
    "            # weights[bad_indices] = 0\n",
    "            # truth_indices[bad_indices] = 0\n",
    "            # loss = - weights * meta_adata.obsm[f\"{key}_class_logits\"][np.arange(len(meta_adata)), truth_indices.astype(int)]\n",
    "            # loss = loss.mean()\n",
    "            # results[f\"{key}_loss\"].append(loss)\n",
    "\n",
    "            # for n_hops in range(N_HOPS_DICT[key] + 1):\n",
    "            #     # accuracy\n",
    "            #     hop_accuracy = meta_adata.obs[f\"{key}_hop_{n_hops}_call\"].dropna().mean()\n",
    "            #     results[f\"{key}_hop_{n_hops}_accuracy\"].append(hop_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_meta_df = pd.read_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_artifacts\", \"cellxgene_validation_donors__third_draft.csv\"))\n",
    "\n",
    "# Stephen's validatdion table\n",
    "# what we have called intestine is actually \"small intestine\"\n",
    "tissue_ontology_term_id_to_coarse_name_map = dict()\n",
    "for row in validation_meta_df['tissue_name_ont_coarsename_coarseont'].values:\n",
    "    split_row = row.strip(\"()\").split(', ')\n",
    "    coarse_name = split_row[2].strip(\"'\")\n",
    "    if coarse_name == \"intestine\":\n",
    "        coarse_name = \"small intestine\"\n",
    "    tissue_ontology_term_id_to_coarse_name_map[split_row[1].strip(\"'\")] = coarse_name\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "val_adata_id_to_coarse_tissue_map = dict()\n",
    "for val_idx in tqdm(range(1, 111)):\n",
    "    \n",
    "    val_adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}.h5ad\")\n",
    "    val_adata = sc.read_h5ad(val_adata_path)\n",
    "\n",
    "    obs_df = val_adata.obs\n",
    "    val_adata_id_to_coarse_tissue_map[val_idx] = obs_df['tissue_ontology_term_id'].map(\n",
    "        tissue_ontology_term_id_to_coarse_name_map).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coarse_tissue'] = df['val_adata_id'].map(val_adata_id_to_coarse_tissue_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PREFIX_LIST = PREFIX_LIST[:3]\n",
    "df = df[df['prefix'].isin(_PREFIX_LIST)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'cell_type'\n",
    "\n",
    "metrics = [\"top_1_accuracy\", \"top_3_accuracy\", \"top_5_accuracy\", \"top_10_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    full_metric = f\"{key}_{metric}\"\n",
    "    df_metric = df[[full_metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(full_metric, np.median),\n",
    "        mean=(full_metric, np.mean),\n",
    "        q1=(full_metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(full_metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err_lower = y_vals - stats['q1']\n",
    "    y_err_upper = stats['q3'] - y_vals\n",
    "    y_err = [y_err_lower.values, y_err_upper.values]\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(key)\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cell_type_top_10_accuracy\", \"tissue_top_10_accuracy\", \"disease_top_10_accuracy\", \"sex_top_1_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    df_metric = df[[metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(metric, np.median),\n",
    "        mean=(metric, np.mean),\n",
    "        q1=(metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err_lower = y_vals - stats['q1']\n",
    "    y_err_upper = stats['q3'] - y_vals\n",
    "    y_err = [y_err_lower.values, y_err_upper.values]\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    # ax.set_ylabel()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cell_type_top_10_accuracy\", \"tissue_top_10_accuracy\", \"disease_top_10_accuracy\", \"sex_top_1_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    df_metric = df[[metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(metric, np.median),\n",
    "        mean=(metric, np.mean),\n",
    "        std=(metric, np.std),\n",
    "        count=(metric, 'count'),\n",
    "        q1=(metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err = stats['std'] / np.sqrt(stats['count'])\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(metric)\n",
    "    # ax.set_ylim((-0.05, 1.05))\n",
    "    # ax.set_ylabel()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "    # --- Half Violin Plot (the \"raincloud\" part) ---\n",
    "    sns.violinplot(\n",
    "        x=\"prefix\", \n",
    "        y=metric, \n",
    "        data=df,\n",
    "        hue=True,\n",
    "        hue_order=[True, False],\n",
    "        split=True,\n",
    "        bw=0.2,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.legend_ = None\n",
    "    # Title etc.\n",
    "    ax.set_title(f\"Distribution of {metric} by prefix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_axis(ax, category, horizontal=False, keep_variable_axis=True):\n",
    "\n",
    "    # Remove the axis lines\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    if horizontal:\n",
    "        ax.set_ylabel(None)\n",
    "        lim = ax.get_ylim()\n",
    "        ax.set_yticks([(lim[0] + lim[1]) / 2])\n",
    "        ax.set_yticklabels([category])\n",
    "        if not keep_variable_axis:\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.spines[\"bottom\"].set_visible(False)\n",
    "    else:\n",
    "        ax.set_xlabel(None)\n",
    "        lim = ax.get_xlim()\n",
    "        ax.set_xticks([(lim[0] + lim[1]) / 2])\n",
    "        ax.set_xticklabels([category], rotation=90)\n",
    "        if not keep_variable_axis:\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "def categorical_kde_plot(\n",
    "    df,\n",
    "    variable,\n",
    "    category,\n",
    "    category_order=None,\n",
    "    horizontal=False,\n",
    "    rug=True,\n",
    "    figsize=None,\n",
    "):\n",
    "    \"\"\"Draw a categorical KDE plot\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The data to plot\n",
    "    variable: str\n",
    "        The column in the `df` to plot (continuous variable)\n",
    "    category: str\n",
    "        The column in the `df` to use for grouping (categorical variable)\n",
    "    horizontal: bool\n",
    "        If True, draw density plots horizontally. Otherwise, draw them\n",
    "        vertically.\n",
    "    rug: bool\n",
    "        If True, add also a sns.rugplot.\n",
    "    figsize: tuple or None\n",
    "        If None, use default figsize of (7, 1*len(categories))\n",
    "        If tuple, use that figsize. Given to plt.subplots as an argument.\n",
    "    \"\"\"\n",
    "    if category_order is None:\n",
    "        categories = list(df[category].unique())\n",
    "    else:\n",
    "        categories = category_order[:]\n",
    "\n",
    "    # figsize = (7, 1.0 * len(categories))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(categories) if horizontal else 1,\n",
    "        ncols=1 if horizontal else len(categories),\n",
    "        figsize=figsize[::-1] if not horizontal else figsize,\n",
    "        sharex=horizontal,\n",
    "        sharey=not horizontal,\n",
    "    )\n",
    "\n",
    "    for i, (cat, ax) in enumerate(zip(categories, axes)):\n",
    "        sns.kdeplot(\n",
    "            data=df[df[category] == cat],\n",
    "            x=variable if horizontal else None,\n",
    "            y=None if horizontal else variable,\n",
    "            # kde kwargs\n",
    "            bw_adjust=0.5,\n",
    "            clip_on=False,\n",
    "            fill=True,\n",
    "            alpha=1,\n",
    "            cut=0,\n",
    "            linewidth=1.5,\n",
    "            ax=ax,\n",
    "            color=\"lightslategray\",\n",
    "        )\n",
    "\n",
    "        keep_variable_axis = (i == len(fig.axes) - 1) if horizontal else (i == 0)\n",
    "\n",
    "        if rug:\n",
    "            sns.rugplot(\n",
    "                data=df[df[category] == cat],\n",
    "                x=variable if horizontal else None,\n",
    "                y=None if horizontal else variable,\n",
    "                ax=ax,\n",
    "                color=\"black\",\n",
    "                height=0.1,\n",
    "            )\n",
    "\n",
    "        _format_axis(\n",
    "            ax,\n",
    "            cat,\n",
    "            horizontal,\n",
    "            keep_variable_axis=keep_variable_axis,\n",
    "        )\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coarse_tissue in df['coarse_tissue'].unique():\n",
    "    for metric in metrics:\n",
    "        fig = categorical_kde_plot(\n",
    "            df[df['coarse_tissue'] == coarse_tissue],\n",
    "            metric,\n",
    "            \"prefix\",\n",
    "            horizontal=False,\n",
    "            figsize=(4, 4),\n",
    "        )\n",
    "\n",
    "        fig.gca().set_title(f\"{coarse_tissue} - {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
