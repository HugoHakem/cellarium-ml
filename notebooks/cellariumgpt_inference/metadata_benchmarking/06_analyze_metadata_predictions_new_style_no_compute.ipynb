{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Analyze metadata predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as t\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set the logging level\n",
    "\n",
    "# Create a handler\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Create and set a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# To suppress the stupid AnnData warning ...\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Transforming to str index.\")\n",
    "\n",
    "from cellarium.ml.utilities.inference.cellarium_gpt_inference import \\\n",
    "    CellariumGPTInferenceContext\n",
    "from cellarium.ml.utilities.inference.metadata_benchmarking.calculate_metrics import \\\n",
    "    calculate_metrics_for_prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/home/mehrtash/data\"\n",
    "METADATA_PREDICTIONS_ROOT_PATH = os.path.join(ROOT_PATH, \"data\", \"metadata_predictions_rand_4091\")\n",
    "PREFIX_LIST = [\n",
    "    \"10M_001_bs1536\",\n",
    "    \"19M_001_bs2048\",\n",
    "    \"30M_001_bs2560\",\n",
    "    \"59M_001_bs3072\"\n",
    "]\n",
    "VAL_ADATA_IDX_RANGE = np.arange(1, 111)\n",
    "N_HOPS_DICT = {\n",
    "    'cell_type': 3,\n",
    "    'development_stage': 3,\n",
    "    'disease': 3,\n",
    "    'tissue': 3,\n",
    "    'sex': 0,\n",
    "}\n",
    "\n",
    "def load_predictions_anndata(val_adata_idx: int, prefix_idx: int) -> sc.AnnData:\n",
    "    path = os.path.join(\n",
    "        METADATA_PREDICTIONS_ROOT_PATH,\n",
    "        PREFIX_LIST[prefix_idx],\n",
    "        f\"extract_{VAL_ADATA_IDX_RANGE[val_adata_idx]}_metadata_prediction_scores.h5ad\")\n",
    "    return sc.read_h5ad(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b921408d0d154ef2a87369a94e8efa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae15d3aa0768485dba47ee1827809daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4a80774dfe475ab2b5fe1a50173da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b9213c24ec403bb30746e8b2e5f016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3581cc4ca546a48bfd60143d84f3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "results = defaultdict(list)\n",
    "top_k_list = [1, 3, 5, 10]\n",
    "\n",
    "for prefix_idx in tqdm(range(len(PREFIX_LIST))):\n",
    "    prefix = PREFIX_LIST[prefix_idx]\n",
    "    \n",
    "    for val_adata_idx in tqdm(range(len(VAL_ADATA_IDX_RANGE))):\n",
    "        val_adata_id = VAL_ADATA_IDX_RANGE[val_adata_idx]\n",
    "        meta_adata = load_predictions_anndata(val_adata_idx, prefix_idx)\n",
    "        results[\"prefix\"].append(prefix)\n",
    "        results[\"val_adata_id\"].append(val_adata_id)\n",
    "\n",
    "        for key in [\"cell_type\", \"disease\", \"development_stage\", \"tissue\", \"sex\"]:            \n",
    "            terms = meta_adata.uns[f\"{key}_ontology_term_ids\"]\n",
    "            mapper = {term: idx for idx, term in enumerate(terms)}\n",
    "\n",
    "            logits_nk = meta_adata.obsm[f\"{key}_class_logits\"]\n",
    "            probs_nk = meta_adata.obsm[f\"{key}_class_probs\"]\n",
    "            labels_n = np.asarray(meta_adata.obs[f\"{key}_ontology_term_id\"].map(mapper).values)\n",
    "\n",
    "            # drop nans\n",
    "            valid_indices = ~np.isnan(labels_n)\n",
    "            probs_nk = probs_nk[valid_indices]\n",
    "            labels_n = labels_n[valid_indices].astype(int)  \n",
    "\n",
    "            if len(labels_n) == 0:\n",
    "                for top_k in top_k_list:\n",
    "                    results[f\"{key}_top_{top_k}_accuracy\"].append(np.nan)\n",
    "                # results[f\"{key}_auc\"].append(np.nan)\n",
    "                results[f\"{key}_loss\"].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            # get top k predictions\n",
    "            for top_k in top_k_list:\n",
    "                top_k_indices = np.argsort(probs_nk, axis=1)[:, -top_k:]\n",
    "                top_k_probs = np.take_along_axis(probs_nk, top_k_indices, axis=1)\n",
    "\n",
    "                # calculate top k accuracy\n",
    "                pred_label_n = np.any(top_k_indices == labels_n[:, None], axis=1).astype(int)\n",
    "                top_k_accuracy = np.mean(pred_label_n)\n",
    "                results[f\"{key}_top_{top_k}_accuracy\"].append(top_k_accuracy)\n",
    "\n",
    "            # # Assume classifier.classes_ gives the full set of classes.\n",
    "            # classes = np.arange(probs_nk.shape[1])\n",
    "            # label_bin_nk = label_binarize(labels_n, classes=classes)\n",
    "            # if len(classes) == 2:\n",
    "            #     # binary AUC\n",
    "            #     auc = roc_auc_score(labels_n, probs_nk[:, 1])\n",
    "            # else:\n",
    "            #     auc = roc_auc_score(label_bin_nk, probs_nk, multi_class='ovr', average='micro')\n",
    "            # results[f\"{key}_auc\"].append(auc)\n",
    "\n",
    "            # loss\n",
    "            truth_names = meta_adata.obs[f\"{key}_ontology_term_id\"].values\n",
    "            truth_indices = np.asarray(list(map(mapper.get, truth_names)))\n",
    "            weights = np.ones_like(truth_indices)\n",
    "            bad_indices = [idx for idx in range(len(truth_names)) if truth_names[idx] not in mapper]\n",
    "            weights[bad_indices] = 0\n",
    "            truth_indices[bad_indices] = 0\n",
    "            loss = - weights * meta_adata.obsm[f\"{key}_class_logits\"][np.arange(len(meta_adata)), truth_indices.astype(int)]\n",
    "            loss = loss.mean()\n",
    "            results[f\"{key}_loss\"].append(loss)\n",
    "\n",
    "            # for n_hops in range(N_HOPS_DICT[key] + 1):\n",
    "            #     # accuracy\n",
    "            #     hop_accuracy = meta_adata.obs[f\"{key}_hop_{n_hops}_call\"].dropna().mean()\n",
    "            #     results[f\"{key}_hop_{n_hops}_accuracy\"].append(hop_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_meta_df = pd.read_csv(\n",
    "    os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_artifacts\", \"cellxgene_validation_donors__third_draft.csv\"))\n",
    "\n",
    "# Stephen's validatdion table\n",
    "# what we have called intestine is actually \"small intestine\"\n",
    "tissue_ontology_term_id_to_coarse_name_map = dict()\n",
    "for row in validation_meta_df['tissue_name_ont_coarsename_coarseont'].values:\n",
    "    split_row = row.strip(\"()\").split(', ')\n",
    "    coarse_name = split_row[2].strip(\"'\")\n",
    "    if coarse_name == \"intestine\":\n",
    "        coarse_name = \"small intestine\"\n",
    "    tissue_ontology_term_id_to_coarse_name_map[split_row[1].strip(\"'\")] = coarse_name\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "val_adata_id_to_coarse_tissue_map = dict()\n",
    "for val_idx in tqdm(range(1, 111)):\n",
    "    \n",
    "    val_adata_path = os.path.join(ROOT_PATH, \"data\", \"cellariumgpt_validation\", f\"extract_{val_idx}.h5ad\")\n",
    "    val_adata = sc.read_h5ad(val_adata_path)\n",
    "\n",
    "    obs_df = val_adata.obs\n",
    "    val_adata_id_to_coarse_tissue_map[val_idx] = obs_df['tissue_ontology_term_id'].map(\n",
    "        tissue_ontology_term_id_to_coarse_name_map).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coarse_tissue'] = df['val_adata_id'].map(val_adata_id_to_coarse_tissue_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PREFIX_LIST = PREFIX_LIST\n",
    "df = df[df['prefix'].isin(_PREFIX_LIST)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'cell_type'\n",
    "\n",
    "metrics = [\"top_1_accuracy\", \"top_3_accuracy\", \"top_5_accuracy\", \"top_10_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    full_metric = f\"{key}_{metric}\"\n",
    "    df_metric = df[[full_metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(full_metric, np.median),\n",
    "        mean=(full_metric, np.mean),\n",
    "        q1=(full_metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(full_metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err_lower = y_vals - stats['q1']\n",
    "    y_err_upper = stats['q3'] - y_vals\n",
    "    y_err = [y_err_lower.values, y_err_upper.values]\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(key)\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cell_type_top_10_accuracy\", \"tissue_top_10_accuracy\", \"disease_top_10_accuracy\", \"sex_top_1_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    df_metric = df[[metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(metric, np.median),\n",
    "        mean=(metric, np.mean),\n",
    "        q1=(metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err_lower = y_vals - stats['q1']\n",
    "    y_err_upper = stats['q3'] - y_vals\n",
    "    y_err = [y_err_lower.values, y_err_upper.values]\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    # ax.set_ylabel()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cell_type_top_10_accuracy\", \"tissue_top_10_accuracy\", \"disease_top_10_accuracy\", \"sex_top_1_accuracy\"]\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_metrics, figsize=(2.5 * n_metrics, 4))\n",
    "\n",
    "for i_metric, metric in enumerate(metrics):\n",
    "    ax = axs[i_metric]\n",
    "\n",
    "    df_metric = df[[metric, \"prefix\"]].copy()\n",
    "    df_metric = df_metric.dropna()\n",
    "    \n",
    "    stats = df_metric.groupby('prefix').agg(\n",
    "        median=(metric, np.median),\n",
    "        mean=(metric, np.mean),\n",
    "        std=(metric, np.std),\n",
    "        count=(metric, 'count'),\n",
    "        q1=(metric, lambda x: x.quantile(0.25)),\n",
    "        q3=(metric, lambda x: x.quantile(0.75))\n",
    "    ).reindex(_PREFIX_LIST)\n",
    "    y_vals = stats['mean']\n",
    "    y_err = stats['std'] / np.sqrt(stats['count'])\n",
    "\n",
    "    ax.errorbar(\n",
    "        np.arange(len(_PREFIX_LIST)), y_vals, yerr=y_err,\n",
    "        fmt='o', color='black', ecolor='black',\n",
    "        capsize=4, markersize=6, linestyle='None'\n",
    "    )\n",
    "\n",
    "    ax.plot(np.arange(len(_PREFIX_LIST)), y_vals)\n",
    "\n",
    "    # rotate the x-axis labels by 90 degrees\n",
    "    ax.set_xticks(np.arange(len(_PREFIX_LIST)))\n",
    "    ax.set_xticklabels(_PREFIX_LIST, rotation=90)\n",
    "    ax.set_title(metric)\n",
    "    # ax.set_ylim((-0.05, 1.05))\n",
    "    # ax.set_ylabel()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "    # --- Half Violin Plot (the \"raincloud\" part) ---\n",
    "    sns.violinplot(\n",
    "        x=\"prefix\", \n",
    "        y=metric, \n",
    "        data=df,\n",
    "        hue=True,\n",
    "        hue_order=[True, False],\n",
    "        split=True,\n",
    "        bw=0.2,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.legend_ = None\n",
    "    # Title etc.\n",
    "    ax.set_title(f\"Distribution of {metric} by prefix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_axis(ax, category, horizontal=False, keep_variable_axis=True):\n",
    "\n",
    "    # Remove the axis lines\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    if horizontal:\n",
    "        ax.set_ylabel(None)\n",
    "        lim = ax.get_ylim()\n",
    "        ax.set_yticks([(lim[0] + lim[1]) / 2])\n",
    "        ax.set_yticklabels([category])\n",
    "        if not keep_variable_axis:\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.spines[\"bottom\"].set_visible(False)\n",
    "    else:\n",
    "        ax.set_xlabel(None)\n",
    "        lim = ax.get_xlim()\n",
    "        ax.set_xticks([(lim[0] + lim[1]) / 2])\n",
    "        ax.set_xticklabels([category], rotation=90)\n",
    "        if not keep_variable_axis:\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "def categorical_kde_plot(\n",
    "    df,\n",
    "    variable,\n",
    "    category,\n",
    "    category_order=None,\n",
    "    horizontal=False,\n",
    "    rug=True,\n",
    "    figsize=None,\n",
    "):\n",
    "    \"\"\"Draw a categorical KDE plot\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The data to plot\n",
    "    variable: str\n",
    "        The column in the `df` to plot (continuous variable)\n",
    "    category: str\n",
    "        The column in the `df` to use for grouping (categorical variable)\n",
    "    horizontal: bool\n",
    "        If True, draw density plots horizontally. Otherwise, draw them\n",
    "        vertically.\n",
    "    rug: bool\n",
    "        If True, add also a sns.rugplot.\n",
    "    figsize: tuple or None\n",
    "        If None, use default figsize of (7, 1*len(categories))\n",
    "        If tuple, use that figsize. Given to plt.subplots as an argument.\n",
    "    \"\"\"\n",
    "    if category_order is None:\n",
    "        categories = list(df[category].unique())\n",
    "    else:\n",
    "        categories = category_order[:]\n",
    "\n",
    "    # figsize = (7, 1.0 * len(categories))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(categories) if horizontal else 1,\n",
    "        ncols=1 if horizontal else len(categories),\n",
    "        figsize=figsize[::-1] if not horizontal else figsize,\n",
    "        sharex=horizontal,\n",
    "        sharey=not horizontal,\n",
    "    )\n",
    "\n",
    "    for i, (cat, ax) in enumerate(zip(categories, axes)):\n",
    "        sns.kdeplot(\n",
    "            data=df[df[category] == cat],\n",
    "            x=variable if horizontal else None,\n",
    "            y=None if horizontal else variable,\n",
    "            # kde kwargs\n",
    "            bw_adjust=0.5,\n",
    "            clip_on=False,\n",
    "            fill=True,\n",
    "            alpha=1,\n",
    "            cut=0,\n",
    "            linewidth=1.5,\n",
    "            ax=ax,\n",
    "            color=\"lightslategray\",\n",
    "        )\n",
    "\n",
    "        keep_variable_axis = (i == len(fig.axes) - 1) if horizontal else (i == 0)\n",
    "\n",
    "        if rug:\n",
    "            sns.rugplot(\n",
    "                data=df[df[category] == cat],\n",
    "                x=variable if horizontal else None,\n",
    "                y=None if horizontal else variable,\n",
    "                ax=ax,\n",
    "                color=\"black\",\n",
    "                height=0.1,\n",
    "            )\n",
    "\n",
    "        _format_axis(\n",
    "            ax,\n",
    "            cat,\n",
    "            horizontal,\n",
    "            keep_variable_axis=keep_variable_axis,\n",
    "        )\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coarse_tissue in df['coarse_tissue'].unique():\n",
    "    for metric in metrics:\n",
    "        fig = categorical_kde_plot(\n",
    "            df[df['coarse_tissue'] == coarse_tissue],\n",
    "            metric,\n",
    "            \"prefix\",\n",
    "            horizontal=False,\n",
    "            figsize=(4, 4),\n",
    "        )\n",
    "\n",
    "        fig.gca().set_title(f\"{coarse_tissue} - {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
