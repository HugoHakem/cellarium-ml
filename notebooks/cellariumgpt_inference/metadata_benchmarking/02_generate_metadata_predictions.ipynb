{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate metadata predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as t\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set the logging level\n",
    "\n",
    "# Create a handler\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Create and set a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# To suppress the stupid AnnData warning ...\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Transforming to str index.\")\n",
    "\n",
    "from cellarium.ml.utilities.inference.cellarium_gpt_inference import \\\n",
    "    CellariumGPTInferenceContext\n",
    "from cellarium.ml.utilities.inference.metadata_benchmarking.calculate_metrics import \\\n",
    "    calculate_metrics_for_prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "cuda_device_index = 0\n",
    "val_adata_index = 1\n",
    "\n",
    "checkpoint_path = \"/home/mehrtash/data/100M_long_run/run_001/lightning_logs/version_3/checkpoints/epoch=5-step=504000.ckpt\"\n",
    "ref_adata_path = \"/home/mehrtash/data/data/extract_0.h5ad\"\n",
    "gene_info_path = \"/home/mehrtash/data/gene_info/gene_info.tsv\"\n",
    "adata_path = f\"/home/mehrtash/data/data/cellariumgpt_validation/extract_{val_adata_index}.h5ad\"\n",
    "ontology_resource_path = \"/home/mehrtash/data/data/cellariumgpt_artifacts/ontology\"\n",
    "output_path = \"/home/mehrtash/data/data/cellariumgpt_artifacts/metadata_predictions/100M_long_run_last\"\n",
    "\n",
    "rng_seed = 42\n",
    "n_cells = 1000\n",
    "n_genes = 4_091\n",
    "gene_selection_method = \"random\"  # \"random\" or \"highly_expressed\"\n",
    "chunk_size = 16\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ontology resources\n",
    "logger.info(\"Loading ontology resources ...\")\n",
    "\n",
    "ontology_benchmarking_resource_path_dict = {\n",
    "    'cell_type': os.path.join(ontology_resource_path, 'cl_benchmarking_resource.pkl'),\n",
    "    'development_stage': os.path.join(ontology_resource_path, 'hsapdv_benchmarking_resource.pkl'),\n",
    "    'disease': os.path.join(ontology_resource_path, 'mondo_benchmarking_resource.pkl'),\n",
    "    'tissue': os.path.join(ontology_resource_path, 'uberon_benchmarking_resource.pkl'),\n",
    "    'sex': os.path.join(ontology_resource_path, 'sex_benchmarking_resource.pkl'),\n",
    "}\n",
    "\n",
    "ontology_propagation_resource_path_dict = {\n",
    "    'cell_type': os.path.join(ontology_resource_path, 'cl_propagation_resource.pkl'),\n",
    "    'development_stage': os.path.join(ontology_resource_path, 'hsapdv_propagation_resource.pkl'),\n",
    "    'disease': os.path.join(ontology_resource_path, 'mondo_propagation_resource.pkl'),\n",
    "    'tissue': os.path.join(ontology_resource_path, 'uberon_propagation_resource.pkl'),\n",
    "    'sex': os.path.join(ontology_resource_path, 'sex_propagation_resource.pkl'),\n",
    "}\n",
    "\n",
    "n_hops_dict = {\n",
    "    'cell_type': 3,\n",
    "    'development_stage': 3,\n",
    "    'disease': 3,\n",
    "    'tissue': 3,\n",
    "    'sex': 0,\n",
    "}\n",
    "\n",
    "ontology_benchmarking_resource_dicts = {}\n",
    "for meta_key, path in ontology_benchmarking_resource_path_dict.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        ontology_benchmarking_resource_dicts[meta_key] = pickle.load(f)\n",
    "\n",
    "ontology_propagation_resource_dicts = {}\n",
    "for meta_key, path in ontology_propagation_resource_path_dict.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        ontology_propagation_resource_dicts[meta_key] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading the model checkpoint from {checkpoint_path} ...\")\n",
    "\n",
    "device = torch.device(f\"cuda:{cuda_device_index}\")\n",
    "\n",
    "ctx = CellariumGPTInferenceContext(\n",
    "    cellarium_gpt_ckpt_path=checkpoint_path,\n",
    "    ref_adata_path=ref_adata_path,\n",
    "    gene_info_tsv_path=gene_info_path,\n",
    "    device=device,\n",
    "    attention_backend=\"mem_efficient\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading the validation AnnData object from {adata_path} ...\")\n",
    "adata = sc.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_genes is not None:\n",
    "    if gene_selection_method == \"highly_expressed\":\n",
    "        logger.info(f\"Using {n_genes} highly expressed genes.\")\n",
    "        X_g = np.asarray(adata.X.sum(0)).flatten()\n",
    "        highly_expressed_gene_indices = np.argsort(X_g)[-n_genes:]\n",
    "        highly_expressed_gene_ids = adata.var_names[highly_expressed_gene_indices]\n",
    "        adata = adata[:, highly_expressed_gene_ids]\n",
    "        n_rand_prompt_vars = None\n",
    "        torch_rng = None\n",
    "    elif gene_selection_method == \"random\":\n",
    "        logger.info(f\"Using {n_genes} random genes (seed = {rng_seed}).\")\n",
    "        torch_rng = torch.Generator().manual_seed(rng_seed)\n",
    "        n_rand_prompt_vars = n_genes\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gene selection method: {gene_selection_method}\")\n",
    "else:\n",
    "    logger.info(f\"Using all genes.\")\n",
    "\n",
    "if n_cells is None:\n",
    "    logger.info(f\"Using all cells.\")\n",
    "else:\n",
    "    n_cells = min(n_cells, len(adata))\n",
    "    logger.info(f\"Using {n_cells} random cells (seed = {rng_seed}).\")\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    adata = adata[rng.choice(len(adata), n_cells, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Predicting metadata for {len(adata)} cells ...\")\n",
    "preds = ctx.predict_metadata_chunked(\n",
    "    adata=adata,\n",
    "    chunk_size=chunk_size,\n",
    "    n_rand_prompt_vars=n_rand_prompt_vars,\n",
    "    rng=torch_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_probs_over_ontology(\n",
    "        class_probs_nk: np.ndarray,\n",
    "        class_names_k: t.List[str],\n",
    "        ontology_resource_dict: dict[str, t.Any],\n",
    ") -> t.Tuple[t.List[str], np.ndarray]:\n",
    "    assert len(class_names_k) == class_probs_nk.shape[1]\n",
    "    all_class_names_q = sorted(ontology_resource_dict.keys())\n",
    "    propagated_class_probs_nq = np.zeros((class_probs_nk.shape[0], len(all_class_names_q)))\n",
    "\n",
    "    given_class_name_to_idx = {class_name: idx for idx, class_name in enumerate(class_names_k)}    \n",
    "    for q, class_name in enumerate(all_class_names_q):\n",
    "        for descendant_name in ontology_resource_dict[class_name][\"all_descendants\"]:\n",
    "            if descendant_name in given_class_name_to_idx:\n",
    "                propagated_class_probs_nq[:, q] += class_probs_nk[:, given_class_name_to_idx[descendant_name]]\n",
    "    return all_class_names_q, propagated_class_probs_nq\n",
    "\n",
    "def convert_meta_adata_to_query_obj_for_scoring(\n",
    "        meta_adata: sc.AnnData,\n",
    "        metadata_key: str):\n",
    "    assert metadata_key + \"_propagated_class_probs\" in meta_adata.obsm\n",
    "    assert metadata_key + \"_propagated_ontology_term_ids\" in meta_adata.uns\n",
    "    query_objs = []\n",
    "    ground_truth_ontology_term_ids = []\n",
    "    obs_index = meta_adata.obs.index.values\n",
    "    for i_cell in range(len(meta_adata)):\n",
    "        obs_row = meta_adata.obs.iloc[i_cell]\n",
    "        ground_truth_ontology_term_id = obs_row[metadata_key + \"_ontology_term_id\"]\n",
    "        query_obj = dict()\n",
    "        query_obj[\"query_cell_id\"] = obs_index[i_cell]\n",
    "        query_obj[\"matches\"] = []\n",
    "        for ontology_term_id, score in zip(\n",
    "                meta_adata.uns[metadata_key + \"_propagated_ontology_term_ids\"],\n",
    "                meta_adata.obsm[metadata_key + \"_propagated_class_probs\"][i_cell]):\n",
    "            query_obj[\"matches\"].append({\n",
    "                \"ontology_term_id\": ontology_term_id,\n",
    "                \"score\": score,\n",
    "            })\n",
    "        query_objs.append(query_obj)\n",
    "        ground_truth_ontology_term_ids.append(ground_truth_ontology_term_id)\n",
    "    return query_objs, ground_truth_ontology_term_ids\n",
    "\n",
    "logger.info(\"Inserting predictions into an AnnData object ...\")\n",
    "# put the predictions back into an AnnData object\n",
    "meta_adata = sc.AnnData(obs=adata.obs.copy())\n",
    "\n",
    "for meta_key, meta_preds in preds.items():\n",
    "    meta_adata.obsm[meta_key + \"_class_logits\"] = meta_preds\n",
    "    meta_adata.obsm[meta_key + \"_class_probs\"] = np.exp(meta_preds)\n",
    "    meta_adata.uns[meta_key + \"_ontology_term_ids\"] = ctx.metadata_ontology_infos[meta_key][\"names\"]\n",
    "    meta_adata.uns[meta_key + \"_labels\"] = ctx.metadata_ontology_infos[meta_key][\"labels\"]\n",
    "\n",
    "# propagate predictions to make them ontologically consistent\n",
    "for meta_key, ontology_resource_dict in ontology_benchmarking_resource_dicts.items():\n",
    "    class_probs_nk = meta_adata.obsm[meta_key + \"_class_probs\"]\n",
    "    all_class_names_q, propagated_class_probs_nq = propagate_probs_over_ontology(\n",
    "        class_probs_nk=class_probs_nk,\n",
    "        class_names_k=meta_adata.uns[meta_key + \"_ontology_term_ids\"],\n",
    "        ontology_resource_dict=ontology_resource_dict,\n",
    "    )\n",
    "    meta_adata.obsm[meta_key + \"_propagated_class_probs\"] = propagated_class_probs_nq\n",
    "    meta_adata.uns[meta_key + \"_propagated_ontology_term_ids\"] = all_class_names_q\n",
    "    meta_adata.uns[meta_key + \"_propagated_labels\"] = list(\n",
    "        map(ontology_propagation_resource_dicts[meta_key]['ontology_term_id_to_label'].get, all_class_names_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_keys = ontology_benchmarking_resource_dicts.keys()\n",
    "\n",
    "results_dfs = []\n",
    "for meta_key in meta_keys:\n",
    "    logger.info(f\"Calculating performance metrics for {meta_key} ...\")\n",
    "    query_objs, ground_truth_ontology_term_ids = convert_meta_adata_to_query_obj_for_scoring(\n",
    "        meta_adata=meta_adata,\n",
    "        metadata_key=meta_key)\n",
    "    results_df = calculate_metrics_for_prediction_output(\n",
    "        model_predictions=query_objs,\n",
    "        ground_truth_ontology_term_ids=ground_truth_ontology_term_ids,\n",
    "        ontology_resource=ontology_benchmarking_resource_dicts[meta_key],\n",
    "        num_hops=n_hops_dict[meta_key])\n",
    "    results_df.columns = [f\"{meta_key}_{col}\" if col != \"query_cell_id\" else col for col in results_df.columns]\n",
    "    results_dfs.append(results_df)\n",
    "\n",
    "# merge results dataframes\n",
    "final_results_df = pd.concat(results_dfs, axis=1)\n",
    "meta_adata.obs.index.name = \"query_cell_id\"\n",
    "meta_adata.obs = pd.concat([meta_adata.obs, final_results_df], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Saving the results to {output_path} ...\")\n",
    "meta_adata_output_file_path = os.path.join(output_path, f\"extract_{val_adata_index}_metadata_prediction_scores.h5ad\")\n",
    "meta_adata.write_h5ad(meta_adata_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
