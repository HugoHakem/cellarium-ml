{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as t\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set the logging level\n",
    "\n",
    "# Create a handler\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Create and set a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# To suppress the stupid AnnData warning ...\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Transforming to str index.\")\n",
    "\n",
    "from cellarium.ml.utilities.inference.cellarium_gpt_inference import \\\n",
    "    CellariumGPTInferenceContext\n",
    "from cellarium.ml.utilities.inference.metadata_benchmarking.calculate_metrics import \\\n",
    "    calculate_metrics_for_prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "cuda_device_index = 0\n",
    "val_adata_index = 1\n",
    "\n",
    "checkpoint_path = \"/home/mehrtash/data/100M_long_run/run_001/lightning_logs/version_3/checkpoints/epoch=5-step=504000.ckpt\"\n",
    "ref_adata_path = \"/home/mehrtash/data/data/extract_0.h5ad\"\n",
    "gene_info_path = \"/home/mehrtash/data/gene_info/gene_info.tsv\"\n",
    "adata_path = f\"/home/mehrtash/data/data/cellariumgpt_validation/extract_{val_adata_index}.h5ad\"\n",
    "ontology_resource_path = \"/home/mehrtash/data/data/cellariumgpt_artifacts/ontology\"\n",
    "output_path = \"/home/mehrtash/data/data/cellariumgpt_artifacts/metadata_predictions/100M_long_run_last\"\n",
    "\n",
    "rng_seed = 42\n",
    "n_cells = 10000\n",
    "n_genes = 4_091\n",
    "gene_selection_method = \"random\"  # \"random\" or \"highly_expressed\"\n",
    "chunk_size = 16\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 17:36:09,593 - __main__ - INFO - Loading ontology resources ...\n"
     ]
    }
   ],
   "source": [
    "# load ontology resources\n",
    "logger.info(\"Loading ontology resources ...\")\n",
    "\n",
    "ontology_benchmarking_resource_path_dict = {\n",
    "    'cell_type': os.path.join(ontology_resource_path, 'cl_benchmarking_resource.pkl'),\n",
    "    'development_stage': os.path.join(ontology_resource_path, 'hsapdv_benchmarking_resource.pkl'),\n",
    "    'disease': os.path.join(ontology_resource_path, 'mondo_benchmarking_resource.pkl'),\n",
    "    'tissue': os.path.join(ontology_resource_path, 'uberon_benchmarking_resource.pkl'),\n",
    "    'sex': os.path.join(ontology_resource_path, 'sex_benchmarking_resource.pkl'),\n",
    "}\n",
    "\n",
    "ontology_propagation_resource_path_dict = {\n",
    "    'cell_type': os.path.join(ontology_resource_path, 'cl_propagation_resource.pkl'),\n",
    "    'development_stage': os.path.join(ontology_resource_path, 'hsapdv_propagation_resource.pkl'),\n",
    "    'disease': os.path.join(ontology_resource_path, 'mondo_propagation_resource.pkl'),\n",
    "    'tissue': os.path.join(ontology_resource_path, 'uberon_propagation_resource.pkl'),\n",
    "    'sex': os.path.join(ontology_resource_path, 'sex_propagation_resource.pkl'),\n",
    "}\n",
    "\n",
    "n_hops_dict = {\n",
    "    'cell_type': 3,\n",
    "    'development_stage': 3,\n",
    "    'disease': 3,\n",
    "    'tissue': 3,\n",
    "    'sex': 0,\n",
    "}\n",
    "\n",
    "ontology_benchmarking_resource_dicts = {}\n",
    "for meta_key, path in ontology_benchmarking_resource_path_dict.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        ontology_benchmarking_resource_dicts[meta_key] = pickle.load(f)\n",
    "\n",
    "ontology_propagation_resource_dicts = {}\n",
    "for meta_key, path in ontology_propagation_resource_path_dict.items():\n",
    "    with open(path, \"rb\") as f:\n",
    "        ontology_propagation_resource_dicts[meta_key] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 17:36:10,323 - __main__ - INFO - Loading the model checkpoint from /home/mehrtash/data/100M_long_run/run_001/lightning_logs/version_3/checkpoints/epoch=5-step=504000.ckpt ...\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading the model checkpoint from {checkpoint_path} ...\")\n",
    "\n",
    "device = torch.device(f\"cuda:{cuda_device_index}\")\n",
    "\n",
    "ctx = CellariumGPTInferenceContext(\n",
    "    cellarium_gpt_ckpt_path=checkpoint_path,\n",
    "    ref_adata_path=ref_adata_path,\n",
    "    gene_info_tsv_path=gene_info_path,\n",
    "    device=device,\n",
    "    attention_backend=\"mem_efficient\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a reference adata\n",
    "adata = sc.read_h5ad(ref_adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 17:36:17,330 - __main__ - INFO - Using 4091 random genes (seed = 42).\n",
      "2025-02-27 17:36:17,331 - __main__ - INFO - Using 10000 random cells (seed = 42).\n"
     ]
    }
   ],
   "source": [
    "if n_genes is not None:\n",
    "    if gene_selection_method == \"highly_expressed\":\n",
    "        logger.info(f\"Using {n_genes} highly expressed genes.\")\n",
    "        X_g = np.asarray(adata.X.sum(0)).flatten()\n",
    "        highly_expressed_gene_indices = np.argsort(X_g)[-n_genes:]\n",
    "        highly_expressed_gene_ids = adata.var_names[highly_expressed_gene_indices]\n",
    "        adata = adata[:, highly_expressed_gene_ids]\n",
    "        n_rand_prompt_vars = None\n",
    "        torch_rng = None\n",
    "    elif gene_selection_method == \"random\":\n",
    "        logger.info(f\"Using {n_genes} random genes (seed = {rng_seed}).\")\n",
    "        torch_rng = torch.Generator().manual_seed(rng_seed)\n",
    "        n_rand_prompt_vars = n_genes\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gene selection method: {gene_selection_method}\")\n",
    "else:\n",
    "    logger.info(f\"Using all genes.\")\n",
    "\n",
    "if n_cells is None:\n",
    "    logger.info(f\"Using all cells.\")\n",
    "else:\n",
    "    n_cells = min(n_cells, len(adata))\n",
    "    logger.info(f\"Using {n_cells} random cells (seed = {rng_seed}).\")\n",
    "    rng = np.random.RandomState(rng_seed)\n",
    "    adata = adata[rng.choice(len(adata), n_cells, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 17:36:22,307 - __main__ - INFO - Predicting metadata for 10000 cells ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df03c36d8d747cc8fafe37eeacd55bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(f\"Predicting metadata for {len(adata)} cells ...\")\n",
    "preds = ctx.predict_metadata_chunked(\n",
    "    adata=adata,\n",
    "    chunk_size=chunk_size,\n",
    "    n_rand_prompt_vars=n_rand_prompt_vars,\n",
    "    rng=torch_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_key = 'cell_type'\n",
    "probs = np.exp(preds[metadata_key])\n",
    "ontology_names = np.asarray(ctx.metadata_ontology_infos[metadata_key]['names'])\n",
    "ontology_labels = np.asarray(ctx.metadata_ontology_infos[metadata_key]['labels'])\n",
    "names_to_labels_map = {n: l for n, l in zip(ontology_names, ontology_labels)}\n",
    "\n",
    "best_indices = np.argmax(probs, -1)\n",
    "best_probs = np.max(probs, -1)\n",
    "best_names = ontology_names[best_indices]\n",
    "best_labels = list(map(names_to_labels_map.get, best_names))\n",
    "\n",
    "new_obs = adata.obs.copy()\n",
    "new_obs['predicted_' + metadata_key] = best_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_type xent loss: 3.58 +/- 2.81\n",
      "development_stage xent loss: 7.35 +/- 2.68\n",
      "disease xent loss: 3.51 +/- 5.61\n",
      "tissue xent loss: 5.31 +/- 3.37\n",
      "sex xent loss: 1.00 +/- 1.52\n"
     ]
    }
   ],
   "source": [
    "for metadata_key in ['cell_type', 'development_stage', 'disease', 'tissue', 'sex']:\n",
    "    truth_term_ids = adata.obs[f\"{metadata_key}_ontology_term_id\"].values\n",
    "\n",
    "    vocab_names = ctx.metadata_ontology_infos[metadata_key][\"names\"]\n",
    "    vocab_names_to_idx = {v: i for i, v in enumerate(vocab_names)}\n",
    "    vocab_names_to_idx[\"unknown\"] = -1\n",
    "    truth_vocab_indices = np.array([vocab_names_to_idx[t] for t in truth_term_ids])\n",
    "    truth_logprobs = preds[metadata_key][np.arange(len(preds[metadata_key])), truth_vocab_indices]\n",
    "    good_indices = np.where(truth_vocab_indices != -1)[0]\n",
    "    truth_logprobs = truth_logprobs[good_indices]\n",
    "    mean_truth_logprobs = -truth_logprobs.mean()\n",
    "    std_truth_logprobs = truth_logprobs.std()\n",
    "    print(f\"{metadata_key} xent loss: {mean_truth_logprobs:.2f} +/- {std_truth_logprobs:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
