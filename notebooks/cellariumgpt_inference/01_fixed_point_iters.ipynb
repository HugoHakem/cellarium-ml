{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed point iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellarium.ml import CellariumModule, CellariumPipeline\n",
    "\n",
    "DEVICE = torch.device('cuda:7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "CHECKPOINTS_PATH = \"/mnt/cellariumgpt-xfer/100M_long_run/run_001/lightning_logs/version_0/checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an AnnData Extract\n",
    "\n",
    "We will use it for category mappings ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an AnnData extract\n",
    "adata_path = os.path.join(ROOT_PATH, \"data\", \"extract_0.h5ad\")\n",
    "adata = sc.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ontology_infos = dict()\n",
    "\n",
    "ref_obs = adata.obs\n",
    "\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"] = dict()\n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"names\"] = list(ref_obs['assay_ontology_term_id'].cat.categories)  \n",
    "gene_ontology_infos[\"assay_ontology_term_id\"][\"labels\"] = list(ref_obs['assay_ontology_term_id'].cat.categories) # just because I am lazy\n",
    "\n",
    "gene_ontology_infos[\"suspension_type\"] = dict()\n",
    "gene_ontology_infos[\"suspension_type\"][\"names\"] = list(ref_obs['suspension_type'].cat.categories)  # for uniformity -- this variable does not have an ontology (does it?)\n",
    "gene_ontology_infos[\"suspension_type\"][\"labels\"] = list(ref_obs['suspension_type'].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene IDs, gene symbols, useful maps\n",
    "model_var_names = np.asarray(adata.var_names)\n",
    "model_var_names_set = set(model_var_names)\n",
    "var_name_to_index_map = {var_name: i for i, var_name in enumerate(model_var_names)}\n",
    "\n",
    "gene_info_tsv_path = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "gene_info_df = pd.read_csv(gene_info_tsv_path, sep=\"\\t\")\n",
    "\n",
    "gene_symbol_to_gene_id_map = dict()\n",
    "for gene_symbol, gene_id in zip(gene_info_df['Gene Symbol'], gene_info_df['ENSEMBL Gene ID']):\n",
    "    if gene_symbol != float('nan'):\n",
    "        gene_symbol_to_gene_id_map[gene_symbol] = gene_id\n",
    "\n",
    "gene_id_to_gene_symbol_map = {gene_id: gene_symbol for gene_symbol, gene_id in gene_symbol_to_gene_id_map.items()}\n",
    "for gene_id in model_var_names:\n",
    "    if gene_id not in gene_id_to_gene_symbol_map:\n",
    "        gene_id_to_gene_symbol_map[gene_id] = gene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a CellariumGPT checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(CHECKPOINTS_PATH, \"epoch=2-step=180000.ckpt\")\n",
    "gpt_model = CellariumModule.load_from_checkpoint(ckpt_path, map_location=DEVICE)\n",
    "\n",
    "# Inject gene categories\n",
    "gpt_model.model.gene_categories = np.asarray(adata.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ontology infos from the TrainTokenizer, which is the first step of the pipeline\n",
    "metadata_ontology_infos = gpt_model.pipeline[0].ontology_infos\n",
    "print(type(metadata_ontology_infos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellarium.ml.models.cellarium_gpt import PredictTokenizer\n",
    "\n",
    "# Rewire the pipeline with a PredictTokenizer\n",
    "predict_tokenizer = PredictTokenizer(\n",
    "    max_total_mrna_umis=100_000,\n",
    "    gene_vocab_sizes={\n",
    "        \"assay\": 19,\n",
    "        \"gene_id\": 36601,\n",
    "        \"gene_value\": 2001,\n",
    "        \"suspension_type\": 2,\n",
    "    },\n",
    "    metadata_vocab_sizes={\n",
    "        \"cell_type\": 890,\n",
    "        \"development_stage\": 191,\n",
    "        \"disease\": 350,\n",
    "        \"sex\": 2,\n",
    "        \"tissue\": 822,\n",
    "    },\n",
    "    ontology_infos=metadata_ontology_infos,\n",
    ")\n",
    "\n",
    "gpt_model.pipeline = CellariumPipeline([\n",
    "    predict_tokenizer,\n",
    "    gpt_model.model,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cellarium.ml.models.cellarium_gpt import CellariumGPT\n",
    "\n",
    "\n",
    "def generate_tokens_from_adata(\n",
    "        adata: sc.AnnData,\n",
    "        gene_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        metadata_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        model_gene_categories: list[str],\n",
    "        obs_index: int | list[int] | None,\n",
    "        query_var_index: list[int],\n",
    "        query_total_mrna_umis: float | None,\n",
    "        metadata_prompt_masks_dict: dict[str, bool],\n",
    "        tokenizer: PredictTokenizer,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ) -> tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "\n",
    "    .. note::\n",
    "      All variables in the AnnData are treated as prompts.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # slice the anndata\n",
    "    if isinstance(obs_index, int):\n",
    "        obs_index = [obs_index]\n",
    "\n",
    "    # save obs before slicing\n",
    "    if obs_index is not None:\n",
    "        adata = adata[obs_index]\n",
    "\n",
    "    # generate gene ids and masks\n",
    "    n_cells = len(adata)\n",
    "    adata_var_names = adata.var_names\n",
    "    model_var_name_to_index_map = {var_name: var_index for var_index, var_name in enumerate(model_gene_categories)}\n",
    "    assert all([var_name in model_var_name_to_index_map for var_name in adata_var_names])\n",
    "    prompt_var_index = [model_var_name_to_index_map[var_name] for var_name in adata_var_names]\n",
    "    n_prompt_vars = len(prompt_var_index)\n",
    "    n_query_vars = len(query_var_index)\n",
    "    n_total_vars = n_prompt_vars + n_query_vars\n",
    "    \n",
    "    # gene id\n",
    "    gene_ids_nc = torch.tensor(\n",
    "        prompt_var_index + query_var_index,\n",
    "        dtype=torch.int64, device=device)[None, :].expand(n_cells, n_total_vars)\n",
    "    \n",
    "    # gene prompt mask\n",
    "    gene_prompt_mask_nc = torch.tensor(\n",
    "        [1] * n_prompt_vars + [0] * n_query_vars,\n",
    "        dtype=torch.bool, device=device)[None, :].expand(n_cells, n_total_vars)\n",
    "    \n",
    "    # gene value\n",
    "    try:\n",
    "        prompt_X_ng = np.asarray(adata.X.todense())\n",
    "    except AttributeError:\n",
    "        prompt_X_ng = adata.X\n",
    "    prompt_gene_value_nc = torch.tensor(prompt_X_ng, dtype=torch.float32, device=device)\n",
    "    query_gene_value_nc = torch.zeros(n_cells, n_query_vars, dtype=torch.float32, device=device)\n",
    "    gene_value_nc = torch.cat([prompt_gene_value_nc, query_gene_value_nc], dim=1)\n",
    "\n",
    "    # total mrna umis\n",
    "    prompt_total_mrna_umis_nc = torch.tensor(\n",
    "        adata.obs[\"total_mrna_umis\"].values,\n",
    "        dtype=torch.float32, device=device)[:, None].expand(n_cells, n_prompt_vars)\n",
    "    if query_total_mrna_umis is None:\n",
    "        # the same as prompt\n",
    "        query_total_mrna_umis_nc = torch.tensor(\n",
    "            adata.obs[\"total_mrna_umis\"].values,\n",
    "            dtype=torch.float32, device=device)[:, None].expand(n_cells, n_query_vars)\n",
    "    else:\n",
    "        query_total_mrna_umis_nc = torch.tensor(\n",
    "            [query_total_mrna_umis] * n_cells,\n",
    "            dtype=torch.float32, device=device)[:, None].expand(n_cells, n_query_vars)\n",
    "    total_mrna_umis_nc = torch.cat([prompt_total_mrna_umis_nc, query_total_mrna_umis_nc], dim=1)\n",
    "\n",
    "    # convert assay and suspension_type to codes\n",
    "    assay_nc = torch.tensor(\n",
    "        pd.Categorical(\n",
    "            adata.obs[\"assay_ontology_term_id\"].values,\n",
    "            categories=gene_ontology_infos[\"assay_ontology_term_id\"][\"names\"]).codes,\n",
    "        dtype=torch.int64, device=device)[:, None].expand(n_cells, n_total_vars)\n",
    "    suspension_type_nc = torch.tensor(\n",
    "        pd.Categorical(\n",
    "            adata.obs[\"suspension_type\"].values,\n",
    "            categories=gene_ontology_infos[\"suspension_type\"][\"names\"]).codes,\n",
    "        dtype=torch.int64, device=device)[:, None].expand(n_cells, n_total_vars)\n",
    "\n",
    "    gene_tokens_dict = {\n",
    "        \"assay\": assay_nc,  # categorical\n",
    "        \"suspension_type\": suspension_type_nc,  # categorical\n",
    "        \"gene_id\": gene_ids_nc,  # categorical\n",
    "        \"gene_value\": gene_value_nc,  # continuous\n",
    "        \"total_mrna_umis\": total_mrna_umis_nc,  # continuous\n",
    "    }\n",
    "\n",
    "    # metadata prompt masks\n",
    "    expanded_metadata_prompt_masks_dict = dict()\n",
    "    for key in metadata_ontology_infos.keys():  # note: key order is important ...\n",
    "        expanded_metadata_prompt_masks_dict[key] = torch.tensor(\n",
    "            [metadata_prompt_masks_dict[key]] * n_cells, dtype=torch.bool, device=device)\n",
    "    \n",
    "    # generate metadata tokens dicts; `PredictTokenizer` will convert these to codes\n",
    "    metadata_tokens_dict = {\n",
    "        \"cell_type\": adata.obs[\"cell_type_ontology_term_id\"].values,  # categorical\n",
    "        \"development_stage\": adata.obs[\"development_stage_ontology_term_id\"].values,  # categorical\n",
    "        \"disease\": adata.obs[\"disease_ontology_term_id\"].values,  # categorical\n",
    "        \"sex\": adata.obs[\"sex_ontology_term_id\"].values,  # categorical\n",
    "        \"tissue\": adata.obs[\"tissue_ontology_term_id\"].values,  # categorical\n",
    "    }\n",
    "\n",
    "    # where to find each thing in the context?\n",
    "    context_indices = dict()\n",
    "    context_indices['prompt_genes'] = np.arange(0, n_prompt_vars).tolist()\n",
    "    context_indices['query_genes'] = np.arange(n_prompt_vars, n_query_vars + n_prompt_vars).tolist()\n",
    "    offset = 0\n",
    "    for metadata_key in metadata_ontology_infos.keys():\n",
    "        context_indices[f'query_{metadata_key}'] = n_query_vars + n_prompt_vars + offset\n",
    "        offset += 1\n",
    "\n",
    "    # return gene_tokens_dict, metadata_tokens_dict\n",
    "    tokenizer_output = tokenizer(\n",
    "        metadata_tokens_n=metadata_tokens_dict,\n",
    "        metadata_prompt_masks_n=expanded_metadata_prompt_masks_dict,\n",
    "        gene_tokens_nc=gene_tokens_dict,\n",
    "        gene_prompt_mask_nc=gene_prompt_mask_nc,\n",
    "    )\n",
    "\n",
    "    return tokenizer_output, context_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metacell fixed point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_marginal_mean_manifold(\n",
    "        adata: sc.AnnData,\n",
    "        gene_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        metadata_ontology_infos: dict[str, dict[str, list[str]]],\n",
    "        query_var_names: list[str],\n",
    "        query_total_mrna_umis: float | None,\n",
    "        predict_tokenizer: PredictTokenizer,\n",
    "        cellarium_gpt_module: CellariumModule,\n",
    "        prompt_gene_values_g: torch.Tensor | None = None,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    assert len(adata) == 1, \"Only a single cell is allowed\"\n",
    "    \n",
    "    model_gene_categories = cellarium_gpt_module.model.gene_categories\n",
    "    var_name_to_index_map = {var_name: i for i, var_name in enumerate(model_gene_categories)}\n",
    "    query_var_index = [var_name_to_index_map[var_name] for var_name in query_var_names]\n",
    "\n",
    "    metadata_prompt_masks_dict = {\n",
    "        \"cell_type\": False,\n",
    "        \"development_stage\": False,\n",
    "        \"disease\": False,\n",
    "        \"sex\": False,\n",
    "        \"tissue\": False,\n",
    "    }\n",
    "\n",
    "    tokens_dict, context_indices = generate_tokens_from_adata(\n",
    "        adata=adata,\n",
    "        gene_ontology_infos=gene_ontology_infos,\n",
    "        metadata_ontology_infos=metadata_ontology_infos,\n",
    "        model_gene_categories=model_var_names,\n",
    "        obs_index=None,\n",
    "        query_var_index=query_var_index,\n",
    "        query_total_mrna_umis=query_total_mrna_umis,\n",
    "        metadata_prompt_masks_dict=metadata_prompt_masks_dict,\n",
    "        tokenizer=predict_tokenizer,\n",
    "        device=torch.device(\"cpu\"),\n",
    "    )\n",
    "\n",
    "    # convert to cuda\n",
    "    tokens_dict = cellarium_gpt_module.transfer_batch_to_device(tokens_dict, cellarium_gpt_module.device, 0)\n",
    "    \n",
    "    # get a reference to prompt gene values\n",
    "    FIRST_CELL_DIM = 0\n",
    "    GENE_VALUE_DIM = 0\n",
    "    prompt_gene_log1p_values_g = tokens_dict['gene_tokens_nc']['gene_value'][\n",
    "        FIRST_CELL_DIM, context_indices['prompt_genes'], GENE_VALUE_DIM]\n",
    "    \n",
    "    # this is the \"source\"\n",
    "    if prompt_gene_values_g is None:\n",
    "        prompt_gene_values_g = torch.expm1(prompt_gene_log1p_values_g).clone()\n",
    "    \n",
    "    # inject back to tokens_dict to re-establish the reference for Jacobian calculation\n",
    "    tokens_dict['gene_tokens_nc']['gene_value'][\n",
    "        FIRST_CELL_DIM, context_indices['prompt_genes'], GENE_VALUE_DIM] = torch.log1p(prompt_gene_values_g)\n",
    "\n",
    "    # get model predictions\n",
    "    logits_dict = cellarium_gpt_module.model.predict(\n",
    "        gene_tokens_nc=tokens_dict[\"gene_tokens_nc\"],\n",
    "        metadata_tokens_n=tokens_dict[\"metadata_tokens_n\"],\n",
    "        prompt_mask_nc=tokens_dict[\"prompt_mask_nc\"],\n",
    "    )\n",
    "\n",
    "    # note: we use `q` to denote query genes\n",
    "    gene_logits_qk = logits_dict['gene_value'][FIRST_CELL_DIM, context_indices['query_genes'], :]\n",
    "    gene_logits_qk = gene_logits_qk - torch.logsumexp(gene_logits_qk, dim=-1, keepdim=True)\n",
    "    log_counts_k = torch.arange(0, gene_logits_qk.shape[-1], device=gene_logits_qk.device).log()\n",
    "    gene_marginal_means_q = torch.logsumexp(gene_logits_qk + log_counts_k[None, :], dim=-1).exp()\n",
    "\n",
    "    return prompt_gene_values_g, gene_marginal_means_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test snap to marginal mean manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a test anndata\n",
    "dataset_name = \"luca_CD8_ex_LUAD\"\n",
    "mode = \"single\"\n",
    "\n",
    "test_adata_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", f\"{dataset_name}.h5ad\")\n",
    "test_adata = sc.read_h5ad(test_adata_path)\n",
    "\n",
    "# add total mNRA umis\n",
    "test_adata.obs['total_mrna_umis'] = test_adata.X.sum(axis=1)\n",
    "\n",
    "# make a metacell\n",
    "if mode == \"meta\":\n",
    "    X_meta_g = np.asarray(test_adata.X.sum(0))\n",
    "\n",
    "    # set total mrna umis to the mean of the dataset\n",
    "    target_total_mrna_umis = np.mean(np.asarray(test_adata.X.sum(-1)).flatten())\n",
    "    X_meta_g = X_meta_g * target_total_mrna_umis / X_meta_g.sum()\n",
    "\n",
    "    # make a metacell anndata\n",
    "    adata_meta = test_adata[0, :].copy()\n",
    "    adata_meta.X = X_meta_g\n",
    "    adata_meta.obs['total_mrna_umis'] = [target_total_mrna_umis]\n",
    "\n",
    "elif mode == \"single\":\n",
    "    # select the first cell\n",
    "    adata_meta = test_adata[0, :].copy()\n",
    "    adata_meta.X = np.asarray(adata_meta.X.todense())\n",
    "\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "# choose top genes\n",
    "top_genes_path = os.path.join(ROOT_PATH, \"cellariumgpt_pd1_lung\", \"output\", \"immune_top_5000_genes.csv\")\n",
    "top_genes_df = pd.read_csv(top_genes_path)\n",
    "top_gene_ids = top_genes_df['gene_id'].values\n",
    "\n",
    "# restrict top_gene_ids to those in the model categories\n",
    "top_gene_ids = [gene_id for gene_id in top_gene_ids if gene_id in model_var_names_set]\n",
    "prompt_gene_ids = top_gene_ids\n",
    "\n",
    "adata_meta = adata_meta[:, prompt_gene_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 5\n",
    "last_gene_values_g = torch.tensor(adata_meta.X[0, :], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "fixed_point_iterations_list = []\n",
    "fixed_point_iterations_list.append(last_gene_values_g.detach().cpu().numpy())\n",
    "\n",
    "for i in range(n_iters):\n",
    "    with torch.inference_mode():\n",
    "        _, gene_marginal_means_q = snap_to_marginal_mean_manifold(\n",
    "            adata=adata_meta,\n",
    "            gene_ontology_infos=gene_ontology_infos,\n",
    "            metadata_ontology_infos=metadata_ontology_infos,\n",
    "            query_var_names=prompt_gene_ids,\n",
    "            query_total_mrna_umis=target_total_mrna_umis,\n",
    "            predict_tokenizer=predict_tokenizer,\n",
    "            cellarium_gpt_module=gpt_model,\n",
    "            prompt_gene_values_g=last_gene_values_g)\n",
    "    \n",
    "    fixed_point_iterations_list.append(gene_marginal_means_q.detach().cpu().numpy())\n",
    "    last_gene_values_g = gene_marginal_means_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for i in range(n_iters):\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    x = fixed_point_iterations_list[i % n_iters]\n",
    "    y = fixed_point_iterations_list[(i + 1) % n_iters]\n",
    "    ax.scatter(x, y, s=1)\n",
    "    ax.set_xlim((1e-4, 1e2))\n",
    "    ax.set_ylim((1e-4, 1e2))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(f'Iteration {i % n_iters}')\n",
    "    ax.set_ylabel(f'Iteration {(i + 1) % n_iters}')\n",
    "    ax.set_title(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the major DE genes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_initial_expression = 0.01\n",
    "mask_g = fixed_point_iterations_list[0] > min_initial_expression\n",
    "ratios_g = np.log10((fixed_point_iterations_list[-1] + 1e-8) / (1e-8 + fixed_point_iterations_list[0]))\n",
    "gene_symbols_g = np.asarray([gene_id_to_gene_symbol_map[gene_id] for gene_id in prompt_gene_ids], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ratios_g = ratios_g[mask_g]\n",
    "_gene_symbols_g = gene_symbols_g[mask_g]\n",
    "\n",
    "sort_order = np.argsort(_ratios_g)[::-1]\n",
    "_ratios_g = _ratios_g[sort_order]\n",
    "_gene_symbols_g = _gene_symbols_g[sort_order]\n",
    "\n",
    "top_k = 20\n",
    "for i in range(top_k):\n",
    "    print(f\"{_gene_symbols_g[i]}: {_ratios_g[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
