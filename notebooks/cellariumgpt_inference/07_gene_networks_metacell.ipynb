{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for flex attention\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "DEVICE = torch.device('cuda:7')\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "\n",
    "from cellarium.ml.utilities.inference.cellarium_gpt_inference import \\\n",
    "    CellariumGPTInferenceContext, JacobianContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "CHECKPOINT_PATH = \"/mnt/cellariumgpt-xfer/100M_long_run/run_001/lightning_logs/version_1/checkpoints/epoch=2-step=252858.ckpt\"\n",
    "REF_ADATA_PATH = os.path.join(ROOT_PATH, \"data\", \"extract_0.h5ad\")\n",
    "GENE_INFO_PATH = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "\n",
    "ctx = CellariumGPTInferenceContext(\n",
    "    cellarium_gpt_ckpt_path=CHECKPOINT_PATH,\n",
    "    ref_adata_path=REF_ADATA_PATH,\n",
    "    gene_info_tsv_path=GENE_INFO_PATH,\n",
    "    device=DEVICE,\n",
    "    attention_backend=\"mem_efficient\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "\n",
    "# dataset_name = \"extract_40__0\"  # neuron\n",
    "dataset_name = \"extract_100__3\"  # CD8+ T cell\n",
    "# dataset_name = \"extract_100__1\"  # monocyte\n",
    "# dataset_name = \"extract_40__1\"  # oligo\n",
    "# dataset_name = \"extract_50__6\"  # CM\n",
    "# dataset_name = \"extract_50__6\"  # CM\n",
    "\n",
    "adata_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", f\"{dataset_name}.h5ad\")\n",
    "\n",
    "jacobian_pt_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", \"matmul_highest_10k\", f\"{dataset_name}__jacobian__marginal_mean.pt\")\n",
    "\n",
    "gene_info_tsv_path = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "\n",
    "OUTPUT_ROOT_PATH = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", \"matmul_highest_10k\", \"analysis\")\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx = JacobianContext.from_old_jacobian_pt_dump(jacobian_pt_path, adata_path, gene_info_tsv_path)\n",
    "print(jac_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.process(\n",
    "    jacobian_normalization_strategy=\"mean\",\n",
    "    feature_normalization_strategy=\"query_z_score\",\n",
    "    query_response_amp_min_pct=10,\n",
    "    min_prompt_gene_tpm=5,\n",
    "    min_query_gene_tpm=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.compute_adjacency_matrix(\n",
    "    adjacency_strategy=\"positive_correlation\",\n",
    "    n_neighbors=10,\n",
    "    beta=6.,\n",
    "    self_loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.compute_leiden_communites(\n",
    "    resolution=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(jac_ctx.leiden_membership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.compute_spectral_dimension(n_lambda_for_estimation=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "jac_ctx.plot_spectral_dimension(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.make_mde_embedding(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_n_gene_symbols = [\n",
    "    'GAP43',\n",
    "    'NRXN3',\n",
    "    'HOMER1',\n",
    "    'IL1RAPL2',\n",
    "    'EPHA3',\n",
    "    'RIMS1',\n",
    "    'SV2B',\n",
    "    'TRIM9',\n",
    "    'SVOP',\n",
    "    'RPH3A',\n",
    "    'SYT12',\n",
    "    'SYT1',\n",
    "    'R3HDM2',\n",
    "    'PDE4B',\n",
    "    'DCC',\n",
    "    'SLC4A10',\n",
    "    'DNM3',\n",
    "    'GRM1',\n",
    "    'EGR4',\n",
    "    'JUNB',\n",
    "    'TFDP2'\n",
    "]\n",
    "\n",
    "snap_n_gene_symbols = [x for x in snap_n_gene_symbols if x in jac_ctx.query_gene_symbols]\n",
    "snap_n_gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[x] for x in snap_n_gene_symbols]\n",
    "\n",
    "muscle_gene_symbols = [\n",
    "    'TTN',\n",
    "    'MYL3',\n",
    "    'MYL4',\n",
    "    'MYL7',\n",
    "    'TNNC1',\n",
    "    'TNNI1',\n",
    "]\n",
    "\n",
    "muscle_gene_symbols = [x for x in muscle_gene_symbols if x in jac_ctx.query_gene_symbols]\n",
    "muscle_gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[x] for x in muscle_gene_symbols]\n",
    "\n",
    "def get_gene_familities(jac_ctx: JacobianContext, prefix_list: list[str]) -> tuple[list[str], list[str]]:\n",
    "    _gene_symbols = [gene_symbol for prefix in prefix_list for gene_symbol in jac_ctx.query_gene_symbols if gene_symbol.startswith(prefix)]\n",
    "    gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[gene_symbol] for gene_symbol in _gene_symbols]\n",
    "    gene_symbols = [jac_ctx.gene_id_to_gene_symbol_map[gene_id] for gene_id in gene_ids]\n",
    "    return gene_ids, gene_symbols\n",
    "\n",
    "mito_gene_ids, mito_gene_symbols = get_gene_familities(jac_ctx, [\"MT-\"])\n",
    "ribo_gene_ids, ribo_gene_symbols = get_gene_familities(jac_ctx, [\"RPS\", \"RPL\"])\n",
    "hla_gene_ids, hla_gene_symbols = get_gene_familities(jac_ctx, [\"HLA\"])\n",
    "ifi_gene_ids, ifi_gene_symbols = get_gene_familities(jac_ctx, [\"IFI\"])\n",
    "\n",
    "highlight_gene_sets = {\n",
    "    \"Mito\": (mito_gene_ids, mito_gene_symbols, 'red'),\n",
    "    \"Ribo\": (ribo_gene_ids, ribo_gene_symbols, 'blue'),\n",
    "    # \"SNAP-n\": (snap_n_gene_ids, snap_n_gene_symbols, 'green'),\n",
    "    # \"HLA\": (hla_gene_ids, hla_gene_symbols, 'green'),\n",
    "    # \"IFI\": (ifi_gene_ids, ifi_gene_symbols, 'orange'),\n",
    "    \"Muscle\": (muscle_gene_ids, muscle_gene_symbols, 'purple'),\n",
    "}\n",
    "\n",
    "# disable\n",
    "# highlight_gene_sets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_ctx.plot_mde_embedding(highlight_gene_sets=highlight_gene_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "\n",
    "# get the dataset names\n",
    "jacobian_pt_root_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", \"matmul_highest_10k\")\n",
    "adata_root_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\")\n",
    "\n",
    "# get the list of files inside jacobian_pt_root_path\n",
    "jacobian_pt_files = os.listdir(jacobian_pt_root_path)\n",
    "jacobian_pt_files = [f for f in jacobian_pt_files if f.endswith(\".pt\")]\n",
    "jacobian_pt_paths = [os.path.join(jacobian_pt_root_path, f) for f in jacobian_pt_files]\n",
    "\n",
    "# extract the file names from the full path\n",
    "# jacobian_pt_files = [os.path.splitext(f)[0] for f in jacobian_pt_files]\n",
    "suffix = \"__jacobian__marginal_mean.pt\"\n",
    "\n",
    "# remove the suffix to get dataset names\n",
    "dataset_names = [f.replace(suffix, \"\") for f in jacobian_pt_files]\n",
    "\n",
    "# generate adata paths\n",
    "adata_paths = [\n",
    "    os.path.join(adata_root_path, f\"{dataset_name}.h5ad\")\n",
    "    for dataset_name in dataset_names]\n",
    "               \n",
    "gene_info_tsv_path = os.path.join(ROOT_PATH, \"gene_info\", \"gene_info.tsv\")\n",
    "\n",
    "output_root_path = os.path.join(jacobian_pt_root_path, \"analysis\")\n",
    "\n",
    "os.makedirs(output_root_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_genes_to_highlight(jac_ctx: JacobianContext) -> dict[str, tuple[list[str], list[str], str]]:\n",
    "    \n",
    "    snap_n_gene_symbols = [\n",
    "        'GAP43',\n",
    "        'NRXN3',\n",
    "        'HOMER1',\n",
    "        'IL1RAPL2',\n",
    "        'EPHA3',\n",
    "        'RIMS1',\n",
    "        'SV2B',\n",
    "        'TRIM9',\n",
    "        'SVOP',\n",
    "        'RPH3A',\n",
    "        'SYT12',\n",
    "        'SYT1',\n",
    "        'R3HDM2',\n",
    "        'PDE4B',\n",
    "        'DCC',\n",
    "        'SLC4A10',\n",
    "        'DNM3',\n",
    "        'GRM1',\n",
    "        'EGR4',\n",
    "        'JUNB',\n",
    "        'TFDP2'\n",
    "    ]\n",
    "\n",
    "    muscle_gene_symbols = [\n",
    "        'TTN',\n",
    "        'MYL3',\n",
    "        'MYL4',\n",
    "        'MYL7',\n",
    "        'TNNC1',\n",
    "        'TNNI1',\n",
    "    ]\n",
    "\n",
    "    snap_n_gene_symbols = [x for x in snap_n_gene_symbols if x in jac_ctx.query_gene_symbols]\n",
    "    snap_n_gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[x] for x in snap_n_gene_symbols]\n",
    "\n",
    "    muscle_gene_symbols = [x for x in muscle_gene_symbols if x in jac_ctx.query_gene_symbols]\n",
    "    muscle_gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[x] for x in muscle_gene_symbols]\n",
    "\n",
    "    def get_gene_familities(jac_ctx: JacobianContext, prefix_list: list[str]) -> tuple[list[str], list[str]]:\n",
    "        _gene_symbols = [\n",
    "            gene_symbol\n",
    "            for prefix in prefix_list\n",
    "            for gene_symbol in jac_ctx.query_gene_symbols\n",
    "            if gene_symbol.startswith(prefix)]\n",
    "        gene_ids = [jac_ctx.gene_symbol_to_gene_id_map[gene_symbol] for gene_symbol in _gene_symbols]\n",
    "        gene_symbols = [jac_ctx.gene_id_to_gene_symbol_map[gene_id] for gene_id in gene_ids]\n",
    "        return gene_ids, gene_symbols\n",
    "\n",
    "    mito_gene_ids, mito_gene_symbols = get_gene_familities(jac_ctx, [\"MT-\"])\n",
    "    ribo_gene_ids, ribo_gene_symbols = get_gene_familities(jac_ctx, [\"RPL\"])\n",
    "    hla_gene_ids, hla_gene_symbols = get_gene_familities(jac_ctx, [\"HLA\"])\n",
    "    ifi_gene_ids, ifi_gene_symbols = get_gene_familities(jac_ctx, [\"IFI\"])\n",
    "\n",
    "    highlight_gene_sets = {\n",
    "        \"Mito\": (mito_gene_ids, mito_gene_symbols, 'red'),\n",
    "        \"Ribo\": (ribo_gene_ids, ribo_gene_symbols, 'blue'),\n",
    "    }\n",
    "\n",
    "    return highlight_gene_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pymde\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_datasets = len(dataset_names)\n",
    "\n",
    "for i_dataset in tqdm(range(n_datasets)):\n",
    "\n",
    "    jacobian_pt_path = jacobian_pt_paths[i_dataset]\n",
    "    adata_path = adata_paths[i_dataset]\n",
    "\n",
    "    # load the jacobian\n",
    "    jac_ctx = JacobianContext.from_old_jacobian_pt_dump(jacobian_pt_path, adata_path, gene_info_tsv_path)\n",
    "    print(jac_ctx)\n",
    "\n",
    "    # process\n",
    "    jac_ctx.process(\n",
    "        jacobian_normalization_strategy=\"mean\",\n",
    "        feature_normalization_strategy=\"query_z_score\",\n",
    "        query_response_amp_min_pct=10,\n",
    "        min_prompt_gene_tpm=10,\n",
    "        min_query_gene_tpm=10)\n",
    "\n",
    "    # adjacency matrix\n",
    "    jac_ctx.compute_adjacency_matrix(\n",
    "        adjacency_strategy=\"positive_correlation\",\n",
    "        n_neighbors=10,\n",
    "        beta=6.,\n",
    "        self_loop=False)\n",
    "\n",
    "    # detect communities\n",
    "    jac_ctx.compute_leiden_communites(\n",
    "        resolution=5.0,\n",
    "        min_community_size=2)\n",
    "\n",
    "    # compute the spectral dimension\n",
    "    jac_ctx.compute_spectral_dimension(n_lambda_for_estimation=10)\n",
    "\n",
    "    # make the spectral dimension plot and save\n",
    "    fig, ax = plt.subplots()\n",
    "    jac_ctx.plot_spectral_dimension(ax=ax)\n",
    "    fig.savefig(\n",
    "        os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__spectral_dimension.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # generate embedding\n",
    "    jac_ctx.make_mde_embedding(\n",
    "            n_neighbors=7,\n",
    "            repulsive_fraction=10,\n",
    "            attractive_penalty=pymde.penalties.Log1p,\n",
    "            repulsive_penalty=pymde.penalties.Log,\n",
    "            device=DEVICE)\n",
    "\n",
    "    # make the embedding plot and save\n",
    "    highlight_gene_sets = generate_genes_to_highlight(jac_ctx)\n",
    "    fig = jac_ctx.plot_mde_embedding(highlight_gene_sets=highlight_gene_sets)\n",
    "    fig.write_image(\n",
    "        os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__embedding.png\"),\n",
    "        scale=2)\n",
    "\n",
    "    # make a dataframe of leiden memberships\n",
    "    community_df = pd.DataFrame({\n",
    "        'gene_ids': jac_ctx.query_var_names,\n",
    "        'gene_symbols': jac_ctx.query_gene_symbols,\n",
    "        'leiden_membership': jac_ctx.leiden_membership})\n",
    "    community_df.to_csv(\n",
    "        os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__leiden_membership.csv\"),\n",
    "        index=False)\n",
    "    \n",
    "    # pickle\n",
    "    with open(os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__jac_ctx.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(jac_ctx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing (GSEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_leiden = len(np.unique(jac_ctx.leiden_membership))\n",
    "# jac_ctx.leiden_to_query_indices = {\n",
    "#     leiden_id: np.where(jac_ctx.leiden_membership == leiden_id)[0]\n",
    "#     for leiden_id in range(n_leiden)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_samples\n",
    "\n",
    "# jac_ctx.silhouette_samples_q = silhouette_samples(jac_ctx.z_qp, jac_ctx.leiden_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jac_ctx.leiden_sillohette_coefficients = []\n",
    "# for leiden_id in range(n_leiden):\n",
    "#     indices = jac_ctx.leiden_to_query_indices[leiden_id]\n",
    "#     scores = jac_ctx.silhouette_samples_q[indices]\n",
    "#     mean_scores = np.mean(scores)\n",
    "#     jac_ctx.leiden_sillohette_coefficients.append(mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# import gseapy as gp\n",
    "\n",
    "\n",
    "# gene_set_path = os.path.join(ROOT_PATH, \"data\", \"gmt\", \"c5.go.v2024.1.Hs.symbols.gmt\")\n",
    "\n",
    "# for leiden_id in tqdm(range(n_leiden)):\n",
    "\n",
    "#     scores = []\n",
    "#     s = set(jac_ctx.leiden_to_query_indices[leiden_id])\n",
    "#     for q in range(len(jac_ctx.query_gene_symbols)):\n",
    "#         if q in s:\n",
    "#             scores.append(1)\n",
    "#         else:\n",
    "#             scores.append(0)\n",
    "        \n",
    "#     gene_list = pd.DataFrame({\n",
    "#         \"gene_symbol\": jac_ctx.query_gene_symbols,\n",
    "#         \"score\": scores}\n",
    "#     )\n",
    "\n",
    "#     output_dir = os.path.join(OUTPUT_ROOT_PATH, dataset_name, f\"leiden_cluster_{leiden_id}\")\n",
    "#     gsea_results = gp.prerank(\n",
    "#         rnk=gene_list,\n",
    "#         gene_sets=gene_set_path,\n",
    "#         min_size=1,\n",
    "#         max_size=5000,\n",
    "#         permutation_num=1000,\n",
    "#         graph_num=90,\n",
    "#         outdir=output_dir\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying gene programs and their relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/mnt/cellariumgpt-xfer/mb-ml-dev-vm\"\n",
    "\n",
    "# get the dataset names\n",
    "jacobian_pt_root_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\", \"matmul_highest_10k\")\n",
    "adata_root_path = os.path.join(\n",
    "    ROOT_PATH, \"data\", \"cellariumgpt_validation\", \"metacells\")\n",
    "\n",
    "# get the list of files inside jacobian_pt_root_path\n",
    "jacobian_pt_files = os.listdir(jacobian_pt_root_path)\n",
    "jacobian_pt_files = [f for f in jacobian_pt_files if f.endswith(\".pt\")]\n",
    "jacobian_pt_paths = [os.path.join(jacobian_pt_root_path, f) for f in jacobian_pt_files]\n",
    "\n",
    "# extract the file names from the full path\n",
    "# jacobian_pt_files = [os.path.splitext(f)[0] for f in jacobian_pt_files]\n",
    "suffix = \"__jacobian__marginal_mean.pt\"\n",
    "\n",
    "# remove the suffix to get dataset names\n",
    "dataset_names = [f.replace(suffix, \"\") for f in jacobian_pt_files]\n",
    "\n",
    "# generate adata paths\n",
    "adata_paths = [\n",
    "    os.path.join(adata_root_path, f\"{dataset_name}.h5ad\")\n",
    "    for dataset_name in dataset_names]\n",
    "\n",
    "output_root_path = os.path.join(jacobian_pt_root_path, \"analysis\")\n",
    "leiden_result_paths = [\n",
    "    os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__leiden_membership.csv\")\n",
    "    for i_dataset in range(len(dataset_names))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a manifest of all available cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "cell_manifest = defaultdict(list)\n",
    "leiden_dict = dict()\n",
    "\n",
    "# vague cell types\n",
    "skip_cell_type_set = {'unknown', 'leukocyte', 'myeloid cell', 'lymphocyte'}\n",
    "\n",
    "for i_dataset in tqdm(range(len(dataset_names))):\n",
    "\n",
    "    adata_path = adata_paths[i_dataset]\n",
    "\n",
    "    # load adata\n",
    "    adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "    # load jac ctx\n",
    "    with open(os.path.join(output_root_path, f\"{dataset_names[i_dataset]}__jac_ctx.pkl\"), \"rb\") as f:\n",
    "        jac_ctx = pickle.load(f)\n",
    "    \n",
    "    cell_type = adata.obs[\"cell_type\"].values[0]\n",
    "\n",
    "    if cell_type in skip_cell_type_set:\n",
    "        continue\n",
    "\n",
    "    cell_manifest[\"dataset_name\"].append(dataset_names[i_dataset])\n",
    "    cell_manifest[\"cell_type\"].append(cell_type)\n",
    "    cell_manifest[\"tissue\"].append(adata.obs[\"tissue\"].values[0])\n",
    "    cell_manifest[\"disease\"].append(adata.obs[\"disease\"].values[0])\n",
    "    cell_manifest[\"development_stage\"].append(adata.obs[\"development_stage\"].values[0])\n",
    "    cell_manifest[\"assay\"].append(adata.obs[\"assay\"].values[0])\n",
    "    cell_manifest[\"suspension_type\"].append(adata.obs[\"suspension_type\"].values[0])\n",
    "\n",
    "    # useful statistics\n",
    "    cell_manifest[\"n_umi\"].append(adata.obs[\"total_mrna_umis\"].values.mean())\n",
    "    cell_manifest[\"n_expr_genes\"].append((adata.X.sum(0) > 0).sum())\n",
    "    cell_manifest[\"n_graph_query_genes\"].append(len(jac_ctx.query_var_names))\n",
    "    cell_manifest[\"n_graph_prompt_genes\"].append(len(jac_ctx.prompt_var_names))\n",
    "    cell_manifest[\"n_leiden_communities\"].append(np.unique(jac_ctx.leiden_membership).size)\n",
    "    cell_manifest[\"spectral_dim\"].append(jac_ctx.spectral_dim)\n",
    "\n",
    "    # process leiden memberships\n",
    "    leiden_ids = np.unique(jac_ctx.leiden_membership)\n",
    "    leiden_ids = [x for x in leiden_ids if x != -1]  # remove -1 labels (unassigned)\n",
    "    _leiden_dict = dict()\n",
    "    for leiden_id in leiden_ids:\n",
    "        indices = np.where(jac_ctx.leiden_membership == leiden_id)[0].tolist()\n",
    "        _leiden_dict[leiden_id] = [jac_ctx.query_gene_symbols[i] for i in indices]\n",
    "    leiden_dict[dataset_names[i_dataset]] = _leiden_dict\n",
    "\n",
    "cell_manifest_df = pd.DataFrame(cell_manifest).sort_values(\"dataset_name\").set_index(\"dataset_name\", drop=True)\n",
    "cell_manifest_df['main_dataset_name'] = cell_manifest_df.index.str.split(\"__\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_manifest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all cells\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(cell_manifest_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "cell_manifest_df.to_csv(os.path.join(output_root_path, \"cell_manifest.csv\"))\n",
    "\n",
    "with open(os.path.join(output_root_path, \"leiden_dict.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(leiden_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard analysis and hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# included_datasets = cell_manifest_df[cell_manifest_df[\"main_dataset_name\"] == \"extract_100\"].index.values\n",
    "included_datasets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a flat leiden dict\n",
    "dataset_leiden_id_to_flat_map = dict()\n",
    "all_communities_flat_gene_lists = []\n",
    "all_communities_flat_gene_sets = []\n",
    "community_labels_tuple = []\n",
    "community_labels = []\n",
    "\n",
    "min_community_size = 5\n",
    "\n",
    "counter = 0\n",
    "for dataset_name, dataset_leiden_dict in leiden_dict.items():\n",
    "    if included_datasets is not None:\n",
    "        if dataset_name not in included_datasets:\n",
    "            continue\n",
    "    dataset_leiden_id_to_flat_map[dataset_name] = dict()\n",
    "    cell_type = cell_manifest_df.loc[dataset_name].cell_type\n",
    "    for leiden_id, gene_list in dataset_leiden_dict.items():\n",
    "        if len(gene_list) < min_community_size:\n",
    "            continue\n",
    "        all_communities_flat_gene_lists.append(gene_list)\n",
    "        all_communities_flat_gene_sets.append(set(gene_list))\n",
    "        dataset_leiden_id_to_flat_map[dataset_name][leiden_id] = counter\n",
    "        community_labels_tuple.append((cell_type, leiden_id))\n",
    "        community_labels.append(f\"{cell_type}, {leiden_id}\")\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Jaccard index between all pairs of communities\n",
    "n_communities = len(all_communities_flat_gene_lists)\n",
    "jaccard_matrix = np.zeros((n_communities, n_communities))\n",
    "\n",
    "for i in tqdm(range(n_communities)):\n",
    "    for j in range(n_communities):\n",
    "        num = len(all_communities_flat_gene_sets[i].intersection(all_communities_flat_gene_sets[j]))\n",
    "        den = len(all_communities_flat_gene_sets[i].union(all_communities_flat_gene_sets[j]))\n",
    "        jaccard_matrix[i, j] = num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from scipy.spatial.distance import squareform\n",
    "\n",
    "# import scipy.cluster.hierarchy as hc\n",
    "\n",
    "# linkage = hc.linkage(squareform(1. - jaccard_matrix), method='ward')\n",
    "\n",
    "# # Convert the matrix to a DataFrame for easier labeling (optional)\n",
    "# labels = [f\"Set {i+1}\" for i in range(jaccard_matrix.shape[0])]\n",
    "# df = pd.DataFrame(jaccard_matrix, index=labels, columns=labels)\n",
    "\n",
    "# # Use Seaborn's clustermap with precomputed distance\n",
    "# sns.set(style=\"white\")\n",
    "\n",
    "# cluster_map = sns.clustermap(\n",
    "#     df,\n",
    "#     row_linkage=linkage,\n",
    "#     col_linkage=linkage,\n",
    "#     linewidths=0,\n",
    "#     cmap='Reds',\n",
    "#     figsize=(10, 10),        # Size of the figure\n",
    "#     dendrogram_ratio=(0.2, 0.2),  # Adjust dendrogram size\n",
    "#     cbar_pos=(0.02, 0.8, 0.03, 0.18)  # Adjust color bar position\n",
    "# )\n",
    "\n",
    "# plt.title('Clustered Heatmap with Precomputed Similarity', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "# Compute linkage for clustering\n",
    "linkage = hc.linkage(squareform(1.0 - jaccard_matrix), method='ward')\n",
    "\n",
    "# Create dendrograms\n",
    "dendro_row = hc.dendrogram(linkage, no_plot=True)\n",
    "dendro_col = hc.dendrogram(linkage, no_plot=True)\n",
    "\n",
    "# Reorder the matrix based on dendrogram leaves\n",
    "heatmap_order = dendro_row['leaves']\n",
    "clustered_matrix = jaccard_matrix[np.ix_(heatmap_order, heatmap_order)]\n",
    "\n",
    "# Labels for the reordered matrix\n",
    "reordered_labels = [community_labels[i] for i in heatmap_order]\n",
    "\n",
    "# Create main dendrogram\n",
    "fig = ff.create_dendrogram(\n",
    "    clustered_matrix,\n",
    "    orientation='bottom',\n",
    "    labels=reordered_labels\n",
    ")\n",
    "fig.for_each_trace(lambda trace: trace.update(visible=False, line=dict(width=1)))\n",
    "\n",
    "for i in range(len(fig['data'])):\n",
    "    fig['data'][i]['yaxis'] = 'y2'\n",
    "\n",
    "# Create side dendrogram\n",
    "dendro_side = ff.create_dendrogram(\n",
    "    clustered_matrix,\n",
    "    orientation='right',\n",
    "    labels=reordered_labels\n",
    ")\n",
    "dendro_side.for_each_trace(lambda trace: trace.update(line=dict(width=1)))\n",
    "\n",
    "for i in range(len(dendro_side['data'])):\n",
    "    dendro_side['data'][i]['xaxis'] = 'x2'\n",
    "\n",
    "# Add side dendrogram data to the figure\n",
    "for data in dendro_side['data']:\n",
    "    fig.add_trace(data)\n",
    "\n",
    "# Create heatmap\n",
    "clustered_matrix_no_diag = clustered_matrix.copy()\n",
    "\n",
    "heatmap = go.Heatmap(\n",
    "    x=reordered_labels,\n",
    "    y=reordered_labels,\n",
    "    z=clustered_matrix,\n",
    "    colorscale='Blues',\n",
    "    zmin=0,\n",
    "    zmax=0.2,\n",
    ")\n",
    "\n",
    "heatmap['x'] = fig['layout']['xaxis']['tickvals']\n",
    "heatmap['y'] = dendro_side['layout']['yaxis']['tickvals']\n",
    "\n",
    "# Add heatmap data to the figure\n",
    "fig.add_trace(heatmap)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    hovermode='closest',\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    xaxis_tickfont = dict(color = 'rgba(0,0,0,0)'),\n",
    ")\n",
    "\n",
    "# Configure x-axis\n",
    "fig.update_layout(\n",
    "    xaxis={\n",
    "        'domain': [.15, 1],\n",
    "        'mirror': False,\n",
    "        'showgrid': False,\n",
    "        'showline': False,\n",
    "        'zeroline': False,\n",
    "        'ticks': \"\"\n",
    "    },\n",
    "    xaxis2={\n",
    "        'domain': [0, .15],\n",
    "        'mirror': False,\n",
    "        'showgrid': False,\n",
    "        'showline': False,\n",
    "        'zeroline': False,\n",
    "        'showticklabels': False,\n",
    "        'ticks': \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure y-axis\n",
    "fig.update_layout(\n",
    "    yaxis={\n",
    "        'domain': [0, 1],\n",
    "        'mirror': False,\n",
    "        'showgrid': False,\n",
    "        'showline': False,\n",
    "        'zeroline': False,\n",
    "        'showticklabels': False,\n",
    "        'ticks': \"\"\n",
    "    },\n",
    "    yaxis2={\n",
    "        'domain': [.825, .975],\n",
    "        'mirror': False,\n",
    "        'showgrid': False,\n",
    "        'showline': False,\n",
    "        'zeroline': False,\n",
    "        'showticklabels': False,\n",
    "        'ticks': \"\"\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_manifest_df.loc[included_datasets][\"cell_type\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_map = {\n",
    "    'CD14-positive monocyte': 'Mono',\n",
    "    'naive thymus-derived CD4-positive, alpha-beta T cell': 'T',\n",
    "    'CD4-positive, alpha-beta cytotoxic T cell': 'T',\n",
    "    'mucosal invariant T cell': 'T',\n",
    "    'CD4-positive, alpha-beta T cell': 'T',\n",
    "    'CD1c-positive myeloid dendritic cell': 'DC',\n",
    "    'monocyte': 'Mono',\n",
    "    'platelet': 'Platelet',\n",
    "    'naive B cell': 'B',\n",
    "    'gamma-delta T cell': 'T',\n",
    "    'central memory CD4-positive, alpha-beta T cell': 'T',\n",
    "    'CD8-positive, alpha-beta cytotoxic T cell': 'T',\n",
    "    'CD16-positive, CD56-dim natural killer cell, human': 'NK',\n",
    "    'CD14-low, CD16-positive monocyte': 'Mono',\n",
    "    'CD8-positive, alpha-beta memory T cell': 'T',\n",
    "    'effector memory CD4-positive, alpha-beta T cell': 'T',\n",
    "    'naive thymus-derived CD8-positive, alpha-beta T cell': 'T',\n",
    "    'memory B cell': 'B',\n",
    "}\n",
    "\n",
    "coarse_reordered_labels = [\n",
    "    coarse_map[', '.join(x.split(', ')[:-1])]\n",
    "    for x in reordered_labels]\n",
    "\n",
    "import colorcet as cc\n",
    "all_coarse_labels = list(set(coarse_reordered_labels))\n",
    "coarse_label_to_color_map = {label: cc.glasbey_light[i] for i, label in enumerate(all_coarse_labels)}\n",
    "reordered_label_colors = [coarse_label_to_color_map[label] for label in coarse_reordered_labels]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# Convert hex colors to an RGB array\n",
    "colors_rgb = [mcolors.hex2color(color) for color in reordered_label_colors]\n",
    "\n",
    "# Reshape the RGB array into a 1-row image\n",
    "color_bar = np.array(colors_rgb).reshape(1, -1, 3)\n",
    "\n",
    "# Display the color bar using imshow\n",
    "plt.figure(figsize=(10, 1))  # Adjust the figure size as needed\n",
    "plt.imshow(color_bar, aspect='auto')\n",
    "plt.axis('off')  # Turn off axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create legend handles\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color=color, label=label)\n",
    "    for label, color in coarse_label_to_color_map.items()\n",
    "]\n",
    "\n",
    "# Create the plot for the legend\n",
    "plt.figure(figsize=(6, 2))  # Adjust the size if needed\n",
    "plt.legend(handles=legend_handles, loc='center', frameon=False)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studying spectral dimension across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_manifest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_col = \"n_umi\"\n",
    "y_col = \"spectral_dim\"\n",
    "\n",
    "x_label = \"Metacell number of UMIs\"\n",
    "y_label = \"Metacell spectral dimension\"\n",
    "\n",
    "x_values = cell_manifest_df[x_col]\n",
    "y_values = cell_manifest_df[y_col]\n",
    "\n",
    "# linear regression with R^2\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "r_squared = np.corrcoef(x_values, y_values)[0, 1] ** 2\n",
    "ax.plot(x_values, slope * x_values + intercept, color='red', label=f\"R^2 = {r_squared:.2f}\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_values,\n",
    "    y_values,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_col = \"n_leiden_communities\"\n",
    "y_col = \"spectral_dim\"\n",
    "\n",
    "x_label = \"Metacell # of leiden communities\"\n",
    "y_label = \"Metacell spectral dimension\"\n",
    "\n",
    "x_values = cell_manifest_df[x_col]\n",
    "y_values = cell_manifest_df[y_col]\n",
    "\n",
    "# linear regression with R^2\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "r_squared = np.corrcoef(x_values, y_values)[0, 1] ** 2\n",
    "ax.plot(x_values, slope * x_values + intercept, color='red', label=f\"R^2 = {r_squared:.2f}\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_values,\n",
    "    y_values,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_manifest_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_col = \"n_graph_query_genes\"\n",
    "y_col = \"spectral_dim\"\n",
    "\n",
    "x_label = \"Metacell # of genes in the graph\"\n",
    "y_label = \"Metacell spectral dimension\"\n",
    "\n",
    "x_values = cell_manifest_df[x_col]\n",
    "y_values = cell_manifest_df[y_col]\n",
    "\n",
    "# linear regression with R^2\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "r_squared = np.corrcoef(x_values, y_values)[0, 1] ** 2\n",
    "ax.plot(x_values, slope * x_values + intercept, color='red', label=f\"R^2 = {r_squared:.2f}\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_values,\n",
    "    y_values,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_col = \"n_graph_prompt_genes\"\n",
    "y_col = \"spectral_dim\"\n",
    "\n",
    "x_label = \"Metacell # of prompt genes\"\n",
    "y_label = \"Metacell spectral dimension\"\n",
    "\n",
    "x_values = cell_manifest_df[x_col]\n",
    "y_values = cell_manifest_df[y_col]\n",
    "\n",
    "# linear regression with R^2\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "r_squared = np.corrcoef(x_values, y_values)[0, 1] ** 2\n",
    "ax.plot(x_values, slope * x_values + intercept, color='red', label=f\"R^2 = {r_squared:.2f}\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_values,\n",
    "    y_values,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_col = \"n_expr_genes\"\n",
    "y_col = \"spectral_dim\"\n",
    "\n",
    "x_label = \"Metacell # of expressed genes\"\n",
    "y_label = \"Metacell spectral dimension\"\n",
    "\n",
    "x_values = cell_manifest_df[x_col]\n",
    "y_values = cell_manifest_df[y_col]\n",
    "\n",
    "# linear regression with R^2\n",
    "slope, intercept = np.polyfit(x_values, y_values, 1)\n",
    "r_squared = np.corrcoef(x_values, y_values)[0, 1] ** 2\n",
    "ax.plot(x_values, slope * x_values + intercept, color='red', label=f\"R^2 = {r_squared:.2f}\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_values,\n",
    "    y_values,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate mean spectral_dim for each cell_type and sort in ascending order\n",
    "mean_spectral_dim = cell_manifest_df.groupby('cell_type')['spectral_dim'].mean().sort_values()\n",
    "\n",
    "# Set cell_type as ordered categorical based on sorted spectral_dim\n",
    "cell_manifest_df['cell_type'] = pd.Categorical(\n",
    "    cell_manifest_df['cell_type'],\n",
    "    categories=mean_spectral_dim.index,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = sns.scatterplot(\n",
    "    x='cell_type',\n",
    "    y='spectral_dim',\n",
    "    hue='main_dataset_name',\n",
    "    data=cell_manifest_df,\n",
    "    s=100\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Spectral dimension by cell type')\n",
    "plt.xlabel('Cell type')\n",
    "plt.ylabel('Spectral dimension')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Get legend handles and labels\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "\n",
    "# Create a mapping from main_dataset_name to main_dataset_name (tissue)\n",
    "legend_labels = []\n",
    "for label in labels[1:]:  # Skip the first label ('main_dataset_name')\n",
    "    tissue = cell_manifest_df.loc[cell_manifest_df['main_dataset_name'] == label, 'tissue'].iloc[0]\n",
    "    legend_labels.append(f\"{label} ({tissue})\")\n",
    "\n",
    "# Update the legend labels\n",
    "plt.legend(handles=handles[1:], labels=legend_labels, title='Metacell source',loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "scatter = sns.boxplot(\n",
    "    x='assay',\n",
    "    y='spectral_dim',\n",
    "    data=cell_manifest_df,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Assay')\n",
    "plt.ylabel('Spectral dimension')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "scatter = sns.boxplot(\n",
    "    x='suspension_type',\n",
    "    y='spectral_dim',\n",
    "    data=cell_manifest_df,\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Suspenstion type')\n",
    "plt.ylabel('Spectral dimension')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load cell manifest\n",
    "cell_manifest_df = pd.read_csv(os.path.join(output_root_path, \"cell_manifest.csv\"), index_col=0)\n",
    "\n",
    "# load communitity\n",
    "with open(os.path.join(output_root_path, \"leiden_dict.pkl\"), \"rb\") as f:\n",
    "    leiden_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# included_datasets = cell_manifest_df[cell_manifest_df[\"main_dataset_name\"] == \"extract_100\"].index.values\n",
    "included_datasets = None\n",
    "\n",
    "# make a flat leiden dict\n",
    "dataset_leiden_id_to_flat_map = dict()\n",
    "all_communities_flat_gene_lists = []\n",
    "all_communities_flat_gene_sets = []\n",
    "community_labels_tuple = []\n",
    "community_labels = []\n",
    "\n",
    "min_community_size = 5\n",
    "\n",
    "counter = 0\n",
    "for dataset_name, dataset_leiden_dict in leiden_dict.items():\n",
    "    if included_datasets is not None:\n",
    "        if dataset_name not in included_datasets:\n",
    "            continue\n",
    "    dataset_leiden_id_to_flat_map[dataset_name] = dict()\n",
    "    cell_type = cell_manifest_df.loc[dataset_name].cell_type\n",
    "    for leiden_id, gene_list in dataset_leiden_dict.items():\n",
    "        if len(gene_list) < min_community_size:\n",
    "            continue\n",
    "        all_communities_flat_gene_lists.append(gene_list)\n",
    "        all_communities_flat_gene_sets.append(set(gene_list))\n",
    "        dataset_leiden_id_to_flat_map[dataset_name][leiden_id] = counter\n",
    "        community_labels_tuple.append((cell_type, leiden_id))\n",
    "        community_labels.append(f\"{cell_type}, {leiden_id}\")\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore, LdaModel\n",
    "\n",
    "# Create a Gensim dictionary from the flattened gene lists\n",
    "dictionary = Dictionary(all_communities_flat_gene_lists)\n",
    "\n",
    "# # Filter extremes (optional, can be adjusted as needed)\n",
    "# dictionary.filter_extremes(no_below=1, no_above=0.5)\n",
    "\n",
    "# Create a bag-of-words (BoW) corpus\n",
    "corpus = [dictionary.doc2bow(community) for community in all_communities_flat_gene_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# Total physical and logical cores\n",
    "logical_cores = os.cpu_count()\n",
    "\n",
    "# Physical cores (if you want more precise control)\n",
    "physical_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Logical cores available: {logical_cores}\")\n",
    "print(f\"Physical cores available: {physical_cores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Enable logging to show progress\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "# Train the LDA model using multiple cores with progress logging\n",
    "num_topics = 200  # Number of topics\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    # alpha='auto',\n",
    "    passes=20,  # Number of passes through the corpus\n",
    "    # workers=128,  # Adjust based on the number of CPU cores\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Print the top words for each topic\n",
    "for topic_id, words_and_probs in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=True):\n",
    "    print(f\"Topic {topic_id}: {words_and_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Example: Extract the top words for each topic\n",
    "topics = []\n",
    "min_prob \n",
    "for topic_id, words_and_probs in lda_model.show_topics(num_topics=num_topics, num_words=50, formatted=False):\n",
    "    topic_words = [word for word, _ in words_and_probs]\n",
    "    topics.append([topic_id] + topic_words)\n",
    "\n",
    "# Define the CSV file path\n",
    "output_csv = \"./output/lda_topics.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header: Topic ID and word columns\n",
    "    writer.writerow([\"Topic ID\"] + [f\"Word {i+1}\" for i in range(10)])\n",
    "    # Write each topic and its words\n",
    "    writer.writerows(topics)\n",
    "\n",
    "print(f\"Topics saved to {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "doc_topic_distributions = []\n",
    "for bow in tqdm(corpus):\n",
    "    doc_topic_distributions.append(lda_model.get_document_topics(bow))\n",
    "\n",
    "# Convert sparse representation to dense, if needed\n",
    "num_topics = lda_model.num_topics\n",
    "doc_topic_dense = [\n",
    "    [dict(topics).get(topic_id, 0) for topic_id in range(num_topics)]\n",
    "    for topics in doc_topic_distributions\n",
    "]\n",
    "\n",
    "doc_topic_dense_np = np.asarray(doc_topic_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an average embedding for each metacell\n",
    "dataset_topic_dense = []\n",
    "dataset_names = []\n",
    "cell_type_names = []\n",
    "\n",
    "for dataset_name, leiden_id_to_flat_map in dataset_leiden_id_to_flat_map.items():\n",
    "    dataset_names.append(dataset_name)\n",
    "    cell_type_names.append(cell_manifest_df.loc[dataset_name].cell_type)\n",
    "    mean_topic_usage = np.mean([\n",
    "        doc_topic_dense_np[flat_id] for flat_id in leiden_id_to_flat_map.values()], axis=0)\n",
    "    mean_topic_usage = mean_topic_usage / np.sum(mean_topic_usage)\n",
    "    dataset_topic_dense.append(mean_topic_usage)\n",
    "\n",
    "dataset_topic_dense_np = np.asarray(dataset_topic_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a UMAP embedding\n",
    "import umap\n",
    "\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "doc_topic_umap_embedding = umap_model.fit_transform(doc_topic_dense_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a UMAP embedding\n",
    "import umap\n",
    "\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "dataset_umap_embedding = umap_model.fit_transform(dataset_topic_dense_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import colorcet as cc\n",
    "import numpy as np\n",
    "\n",
    "# Inputs\n",
    "# Assume community_labels_tuple is a list of (str, int)\n",
    "# Assume doc_topic_umap_embedding is an N x 2 numpy array\n",
    "\n",
    "# Extract the labels (str) from community_labels_tuple\n",
    "labels = [label[0] for label in community_labels_tuple]\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = list(set(labels))\n",
    "\n",
    "# Assign unique colors using colorcet Glasbey\n",
    "glasbey_colors = cc.glasbey[:len(unique_labels)]  # Glasbey has many colors, use as needed\n",
    "label_to_color = {label: glasbey_colors[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'x': doc_topic_umap_embedding[:, 0],  # First dimension of UMAP embedding\n",
    "    'y': doc_topic_umap_embedding[:, 1],  # Second dimension of UMAP embedding\n",
    "    'label': labels  # Labels from community_labels_tuple\n",
    "})\n",
    "\n",
    "# Map colors to the labels\n",
    "df['color'] = df['label'].map(label_to_color)\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    color='label',  # Unique color for each label\n",
    "    title='Scatter Plot with UMAP Embedding',\n",
    "    labels={'label': 'Community Label'},  # Legend label\n",
    "    hover_name='label',  # Display label on hover\n",
    "    color_discrete_map=label_to_color  # Use custom Glasbey colors\n",
    ")\n",
    "\n",
    "# Make markers smaller\n",
    "fig.update_traces(marker=dict(size=2))  # Adjust the size as needed\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1500,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import colorcet as cc\n",
    "import numpy as np\n",
    "\n",
    "# Extract the labels (str) from community_labels_tuple\n",
    "labels = cell_type_names\n",
    "emb = dataset_umap_embedding\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = list(set(labels))\n",
    "\n",
    "# Assign unique colors using colorcet Glasbey\n",
    "glasbey_colors = cc.glasbey[:len(unique_labels)]  # Glasbey has many colors, use as needed\n",
    "label_to_color = {label: glasbey_colors[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'x': emb[:, 0],  # First dimension of UMAP embedding\n",
    "    'y': emb[:, 1],  # Second dimension of UMAP embedding\n",
    "    'label': labels  # Labels from community_labels_tuple\n",
    "})\n",
    "\n",
    "# Map colors to the labels\n",
    "df['color'] = df['label'].map(label_to_color)\n",
    "\n",
    "# Create a scatter plot with text annotations for labels\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='x',\n",
    "    y='y',\n",
    "    color='label',  # Unique color for each label\n",
    "    title='Scatter Plot with UMAP Embedding',\n",
    "    labels={'label': 'Community Label'},  # Legend label\n",
    "    hover_name='label',  # Display label on hover\n",
    "    color_discrete_map=label_to_color,  # Use custom Glasbey colors\n",
    "    text='label'  # Add text annotations\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(size=10, opacity=0.7),\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=8)  # Set font size for labels\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    width=1500,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
