{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('/home/jupyter/NMF.ckpt'):\n",
    "    print(\"trained checkpoint saved\")\n",
    "else:\n",
    "    # fit cnmf\n",
    "    !cellarium-ml nmf fit -c /home/jupyter/yaml/nmf_heart_config_default.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "parent_dir = os.path.dirname('/home/jupyter/')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import anndata\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellarium.ml.core import CellariumPipeline, CellariumModule\n",
    "from cellarium.ml.utilities.data import AnnDataField, densify\n",
    "from cellarium.ml.core.datamodule import CellariumAnnDataDataModule\n",
    "from cellarium.ml.data import (\n",
    "    DistributedAnnDataCollection,\n",
    "    IterableDistributedAnnDataCollectionDataset,\n",
    ")\n",
    "\n",
    "from cellarium.ml.models.nmf import calculate_rec_error, get_embeddding, update_consensusD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutosizedDistributedAnnDataCollection(DistributedAnnDataCollection):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # I'm being lazy here and doing something real ugly\n",
    "        # I want it to take the shard_size from the first file\n",
    "        try:\n",
    "            # this allows super to find the list of filenames\n",
    "            super().__init__(*args, **kwargs)\n",
    "        except AssertionError:\n",
    "            try:\n",
    "                # this allows super to create the cache\n",
    "                kwargs.pop(\"shard_size\")\n",
    "                kwargs = kwargs | {\"shard_size\": 10000}\n",
    "                super().__init__(*args, **kwargs)\n",
    "            except AssertionError:\n",
    "                pass\n",
    "            # load first file and cache it\n",
    "            adata0 = self.cache[self.filenames[0]] = read_h5ad_file(self.filenames[0])\n",
    "            # pull shard_size from that file\n",
    "            kwargs.pop(\"shard_size\")\n",
    "            kwargs = kwargs | {\"shard_size\": len(adata0)}\n",
    "            # finally initialize for real\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "def get_pretrained_model_as_pipeline(\n",
    "    trained_model: str = \"../\", \n",
    "    transforms: list[torch.nn.Module] = [],\n",
    "    device: str = \"cuda\",\n",
    ") -> CellariumPipeline:\n",
    "\n",
    "    model = CellariumModule.load_from_checkpoint(trained_model).model\n",
    "\n",
    "    # insert the trained model params\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # construct the pipeline\n",
    "    pipeline = CellariumPipeline(transforms + [model])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def get_dataset_from_anndata(\n",
    "    adata: anndata.AnnData | str, \n",
    "    batch_size: int = 2048, \n",
    "    shard_size: int | None = None, \n",
    "    shuffle: bool = False, \n",
    "    seed: int = 0, \n",
    "    drop_last: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get IterableDistributedAnnDataCollectionDataset from an AnnData object or h5ad file specifier.\n",
    "\n",
    "    Args:\n",
    "        adata: AnnData object or h5ad file, allowing brace notation for several files.\n",
    "        batch_size: Batch size.\n",
    "        shard_size: Shard size.\n",
    "        shuffle: Whether to shuffle the dataset.\n",
    "        seed: Random seed.\n",
    "        drop_last: Whether to drop the last incomplete batch.\n",
    "\n",
    "    Returns:\n",
    "        IterableDistributedAnnDataCollectionDataset.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(adata, anndata.AnnData):\n",
    "        tmpfile = tempfile.mkstemp(suffix='.h5ad')\n",
    "        adata.write(tmpfile[1])\n",
    "        file = tmpfile[1]\n",
    "    else:\n",
    "        file = adata\n",
    "\n",
    "    dadc = AutosizedDistributedAnnDataCollection(\n",
    "        file,\n",
    "        shard_size=shard_size,\n",
    "        max_cache_size=1,\n",
    "    )\n",
    "\n",
    "    dataset = IterableDistributedAnnDataCollectionDataset(\n",
    "        dadc,\n",
    "        batch_keys={\n",
    "            \"x_ng\": AnnDataField(attr=\"X\", convert_fn=densify),\n",
    "            \"var_names_g\": AnnDataField(attr=\"var_names\"),\n",
    "        },\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        drop_last=drop_last,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_file = \"../yaml/nmf_heart_config_notebook.yaml\"\n",
    "checkpoint_file = '../NMF.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load trained pipeline\n",
    "pipeline = get_pretrained_model_as_pipeline(\n",
    "    trained_model=checkpoint_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is coming from /home/jupyter/data/human_heart_atlas_hvg_scvi_rec.h5ad\n"
     ]
    }
   ],
   "source": [
    "# get the location of the dataset\n",
    "with open(config_file, \"r\") as file:\n",
    "    config_dict = yaml.safe_load(file)\n",
    "data_path = config_dict['data']['dadc']['init_args']['filenames']\n",
    "print(f'Data is coming from {data_path}')\n",
    "\n",
    "# get a dataset object\n",
    "dataset = get_dataset_from_anndata(\n",
    "    data_path, \n",
    "    batch_size=2048,\n",
    "    shard_size=665234,\n",
    "    shuffle=False, \n",
    "    seed=0, \n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate consensus D for all Ks\n",
    "density_threshold = 0.2\n",
    "local_neighborhood_size = 0.3\n",
    "consensus_stat = update_consensusD(pipeline,\n",
    "                                   density_threshold = density_threshold, \n",
    "                                   local_neighborhood_size = local_neighborhood_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = pipeline[-1].k_range\n",
    "\n",
    "for k in k_range:\n",
    "    print('k='+str(k))\n",
    "    \n",
    "    sc.set_figure_params(scanpy=True, dpi=75, dpi_save=75, vector_friendly=True)\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.clustermap(consensus_stat[k]['topk_euc_dist'].cpu().numpy())\n",
    "    plt.show()\n",
    "    \n",
    "    sns.histplot(consensus_stat[k]['local_neigh_dist'].cpu().numpy())\n",
    "    ymax = plt.gca().get_ylim()[1]\n",
    "    plt.vlines(density_threshold, ymin=0, ymax=ymax, color='Red')\n",
    "    plt.xlabel('Mean distance to k nearest neigbors')\n",
    "    plt.ylim(0, ymax)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 325/325 [36:36<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# calculate reconstruction error\n",
    "rec_errors = calculate_rec_error(dataset, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_range = pipeline[-1].k_range\n",
    "silhouette_scores = {}\n",
    "for k in k_range:\n",
    "    silhouette_scores[k] = consensus_stat[k]['stability']\n",
    "eval_metrics = pd.DataFrame.from_dict(silhouette_scores, orient='index')\n",
    "eval_metrics.columns = ['stability']\n",
    "eval_metrics['rec_error'] = rec_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(scanpy=True, dpi=75, dpi_save=75, vector_friendly=True, fontsize=10)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.plot(eval_metrics.index, eval_metrics['stability'], \n",
    "         color='Red', label='Stabibility')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.twinx()\n",
    "plt.plot(eval_metrics.index, eval_metrics['rec_error'], \n",
    "         color='Blue', label='Reconstruction error')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 325/325 [02:35<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# get cell loading with best K\n",
    "adata = get_embeddding(dataset, pipeline, the_best_k=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualization with UMAP\n",
    "reducer = cuml.UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=2,\n",
    "    n_epochs=500,\n",
    "    min_dist=0.15,\n",
    "    metric='cosine'\n",
    ")\n",
    "embedding = reducer.fit_transform(adata.obsm['X_nmf'])\n",
    "adata.obsm['X_nmf_umap'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(scanpy=True, dpi=75, dpi_save=75, vector_friendly=True, fontsize=7.5)\n",
    "sc.pl.embedding(adata, basis='nmf_umap', color=['cell_type', 'cell_state', 'batch'], ncols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cellarium",
   "name": "common-cu122.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu122:m121"
  },
  "kernelspec": {
   "display_name": "cellarium (Local)",
   "language": "python",
   "name": "cellarium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
